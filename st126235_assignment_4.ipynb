{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "82a0beb0",
   "metadata": {},
   "source": [
    "# A4: Do you AGREE?\n",
    "\n",
    "**by Dechathon Niamsa-ard [st126235]**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cca3dc2",
   "metadata": {},
   "source": [
    "### Import Necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fd473df9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\USER\\Documents\\Dechathon_N\\AIT\\Natural Language Understanding\\A4-Do-you-AGREE\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Standard library imports\n",
    "import math\n",
    "import os\n",
    "import pickle\n",
    "import re\n",
    "from random import *\n",
    "\n",
    "# Third-party imports\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# Hugging Face imports\n",
    "import datasets\n",
    "from datasets import load_dataset\n",
    "from datasets import DatasetDict\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import get_linear_schedule_with_warmup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "802678e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch Version: 2.10.0+cu130\n",
      "CUDA Version used by PyTorch: 13.0\n",
      "GPU Name: NVIDIA GeForce RTX 5060 Ti\n",
      "GPU Capability: (12, 0)\n",
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Set device to GPU if available\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"PyTorch Version: {torch.__version__}\")\n",
    "print(f\"CUDA Version used by PyTorch: {torch.version.cuda}\")\n",
    "print(f\"GPU Name: {torch.cuda.get_device_name(0)}\")\n",
    "print(f\"GPU Capability: {torch.cuda.get_device_capability(0)}\")\n",
    "print(f'Using device: {device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f95540b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seed for reproducibility\n",
    "SEED = 1234\n",
    "torch.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f6219f8",
   "metadata": {},
   "source": [
    "## Task 1. Training BERT from Scratch\n",
    "**Based on Masked Language Model/BERT-update.ipynb, modify as follows: (2 points)**\n",
    "\n",
    "1) Implement Bidirectional Encoder Representations from Transformers (BERT) from scratch, following the concepts learned in class.\n",
    "2) Train the model on a suitable dataset. Ensure to source this dataset from reputable public databases or repositories.\n",
    "   * It is imperative to give proper credit to the dataset source in your documentation.\n",
    "3) Save the trained model weights for later use in Task 2.\n",
    "\n",
    "**NOTE:** BERT-update.ipynb is available to use CUDA.\n",
    "\n",
    "**NOTE:** You may refer to the BERT paper and use large corpora such as BookCorpus or English Wikipedia. However, you should only use a subset, such as 100k samples, rather than the entire dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01af8d6e",
   "metadata": {},
   "source": [
    "### Select the Dataset\n",
    "\n",
    "I use the **WikiText-103** dataset from Salesforce for pre-training BERT. WikiText-103 is a large-scale language modeling dataset containing over 100 million tokens extracted from verified Good and Featured articles on Wikipedia. It provides high-quality, long-form text that is well-suited for learning contextual word representations.\n",
    "\n",
    "The dataset is divided into three standard splits:\n",
    "\n",
    "* **Train:** 1,801,350 rows\n",
    "* **Validation:** 3,760 rows\n",
    "* **Test:** 4,358 rows\n",
    "\n",
    "I load the first 300,000 samples and filter out short entries (less than 50 characters) to ensure meaningful training data. This subset provides a good balance between training quality and computational feasibility.\n",
    "\n",
    "**Dataset source:** https://huggingface.co/datasets/Salesforce/wikitext\n",
    "\n",
    "```bibtex\n",
    "@misc{merity2016pointer,\n",
    "      title={Pointer Sentinel Mixture Models},\n",
    "      author={Stephen Merity and Caiming Xiong and James Bradbury and Richard Socher},\n",
    "      year={2016},\n",
    "      eprint={1609.07843},\n",
    "      archivePrefix={arXiv},\n",
    "      primaryClass={cs.CL}\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c999d55d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text'],\n",
       "    num_rows: 132183\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the WikiText-103 dataset\n",
    "dataset = load_dataset(\"wikitext\", \"wikitext-103-raw-v1\", split=\"train[:300000]\")\n",
    "\n",
    "# Filter out low character count samples\n",
    "dataset = dataset.filter(lambda x: len(x[\"text\"].strip()) > 50)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ee0661b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 1:\n",
      " Senjō no Valkyria 3 : Unrecorded Chronicles ( Japanese : 戦場のヴァルキュリア3 , lit . Valkyria of the Battlefield 3 ) , commonly referred to as Valkyria Chronicles III outside Japan , is a tactical role @-@ playing video game developed by Sega and Media.Vision for the PlayStation Portable . Released in January 2011 in Japan , it is the third game in the Valkyria series . Employing the same fusion of tactical and real @-@ time gameplay as its predecessors , the story runs parallel to the first game and follows the \" Nameless \" , a penal military unit serving the nation of Gallia during the Second Europan War who perform secret black operations and are pitted against the Imperial unit \" Calamaty Raven \" . \n",
      "\n",
      "Sample 2:\n",
      " The game began development in 2010 , carrying over a large portion of the work done on Valkyria Chronicles II . While it retained the standard features of the series , it also underwent multiple adjustments , such as making the game more forgiving for series newcomers . Character designer Raita Honjou and composer Hitoshi Sakimoto both returned from previous entries , along with Valkyria Chronicles II director Takeshi Ozawa . A large team of writers handled the script . The game 's opening theme was sung by May 'n . \n",
      "\n",
      "Sample 3:\n",
      " It met with positive sales in Japan , and was praised by both Japanese and western critics . After release , it received downloadable content , along with an expanded edition in November of that year . It was also adapted into manga and an original video animation series . Due to low sales of Valkyria Chronicles II , Valkyria Chronicles III was not localized , but a fan translation compatible with the game 's expanded edition was released in 2014 . Media.Vision would return to the franchise with the development of Valkyria : Azure Revolution for the PlayStation 4 . \n",
      "\n",
      "Sample 4:\n",
      " As with previous Valkyira Chronicles games , Valkyria Chronicles III is a tactical role @-@ playing game where players take control of a military unit and take part in missions against enemy forces . Stories are told through comic book @-@ like panels with animated character portraits , with characters speaking partially through voiced speech bubbles and partially through unvoiced text . The player progresses through a series of linear missions , gradually unlocked as maps that can be freely scanned through and replayed as they are unlocked . The route to each story location on the map varies depending on an individual player 's approach : when one option is selected , the other is sealed off to the player . Outside missions , the player characters rest in a camp , where units can be customized and character growth occurs . Alongside the main story missions are character @-@ specific sub missions relating to different squad members . After the game 's completion , additional episodes are unlocked , some of them having a higher difficulty than those found in the rest of the game . There are also love simulation elements related to the game 's two main heroines , although they take a very minor role . \n",
      "\n",
      "Sample 5:\n",
      " The game 's battle system , the BliTZ system , is carried over directly from Valkyira Chronicles . During missions , players select each unit using a top @-@ down perspective of the battlefield map : once a character is selected , the player moves the character around the battlefield in third @-@ person . A character can only act once per @-@ turn , but characters can be granted multiple turns at the expense of other characters ' turns . Each character has a field and distance of movement limited by their Action Gauge . Up to nine characters can be assigned to a single mission . During gameplay , characters will call out if something happens to them , such as their health points ( HP ) getting low or being knocked out by enemy attacks . Each character has specific \" Potentials \" , skills unique to each character . They are divided into \" Personal Potential \" , which are innate skills that remain unaltered unless otherwise dictated by the story and can either help or impede a character , and \" Battle Potentials \" , which are grown throughout the game and always grant boons to a character . To learn Battle Potentials , each character has a unique \" Masters Table \" , a grid @-@ based skill table that can be used to acquire and link different skills . Characters also have Special Abilities that grant them temporary boosts on the battlefield : Kurt can activate \" Direct Command \" and move around the battlefield without depleting his Action Point gauge , the character Reila can shift into her \" Valkyria Form \" and become invincible , while Imca can target multiple enemy units with her heavy weapon . \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Display the first 5 samples from the dataset\n",
    "for i in range(5):\n",
    "    print(f\"Sample {i+1}:\\n{dataset[i]['text']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "83e700a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " senjō no valkyria 3 : unrecorded chronicles ( japanese : 戦場のヴァルキュリア3  lit  valkyria of the battlefield 3 )  commonly referred to as valkyria chronicles iii outside japan  is a tactical role @@ playing video game developed by sega and mediavision for the playstation portable  released in january 2011 in japan  it is the third game in the valkyria series  employing the same fusion of tactical and real @@ time gameplay as its predecessors  the story runs parallel to the first game and follows the \" nameless \"  a penal military unit serving the nation of gallia during the second europan war who perform secret black operations and are pitted against the imperial unit \" calamaty raven \"  \n",
      " _____\n",
      "['senjō', 'no', 'valkyria', '3', ':', 'unrecorded', 'chronicles', '(', 'japanese', ':', '戦場のヴァルキュリア3', 'lit', 'valkyria', 'of', 'the', 'battlefield', '3', ')', 'commonly', 'referred', 'to', 'as', 'valkyria', 'chronicles', 'iii', 'outside', 'japan', 'is', 'a', 'tactical', 'role', '@@', 'playing', 'video', 'game', 'developed', 'by', 'sega', 'and', 'mediavision', 'for', 'the', 'playstation', 'portable', 'released', 'in', 'january', '2011', 'in', 'japan', 'it', 'is', 'the', 'third', 'game', 'in', 'the', 'valkyria', 'series', 'employing', 'the', 'same', 'fusion', 'of', 'tactical', 'and', 'real', '@@', 'time', 'gameplay', 'as', 'its', 'predecessors', 'the', 'story', 'runs', 'parallel', 'to', 'the', 'first', 'game', 'and', 'follows', 'the', '\"', 'nameless', '\"', 'a', 'penal', 'military', 'unit', 'serving', 'the', 'nation', 'of', 'gallia', 'during', 'the', 'second', 'europan', 'war', 'who', 'perform', 'secret', 'black', 'operations', 'and', 'are', 'pitted', 'against', 'the', 'imperial', 'unit', '\"', 'calamaty', 'raven', '\"']\n"
     ]
    }
   ],
   "source": [
    "# Preprocess the text data by converting to lowercase and removing punctuation\n",
    "sentences = dataset['text']\n",
    "text = [x.lower() for x in sentences] #lower case\n",
    "text = [re.sub(\"[.,!?\\\\-]\", '', x) for x in text] #clean all symbols\n",
    "# text\n",
    "\n",
    "# Display the first sentence and its tokenized form\n",
    "for sentence in text:\n",
    "    print(sentence, \"_____\")\n",
    "    words = sentence.split()\n",
    "    print(words)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c39eb393",
   "metadata": {},
   "source": [
    "### Making vocabs\n",
    "\n",
    "Build a word-level vocabulary from the preprocessed WikiText data. Each unique word is assigned a unique integer ID. Reserve special token IDs for:\n",
    "- `[PAD]` (ID: 0): Padding token to fill sequences to equal length\n",
    "- `[CLS]` (ID: 1): Classification token placed at the beginning of each input\n",
    "- `[SEP]` (ID: 2): Separator token placed between and after sentences\n",
    "- `[MASK]` (ID: 3): Mask token used for Masked Language Modeling during pre-training\n",
    "\n",
    "Also create a reverse mapping (`id2word`) for converting token IDs back to words during inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7570443b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating word2id: 199401it [00:00, 2556452.08it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "199405"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Combine everything into one to make vocab\n",
    "word_list = list(set(\" \".join(text).split()))\n",
    "word2id = {'[PAD]': 0, '[CLS]': 1, '[SEP]': 2, '[MASK]': 3} # Special tokens\n",
    "\n",
    "# Create the word2id in a single pass\n",
    "for i, w in tqdm(enumerate(word_list), desc=\"Creating word2id\"):\n",
    "    word2id[w] = i + 4  # because 0-3 are already occupied\n",
    "\n",
    "# Precompute the id2word mapping (this can be done once after word2id is fully populated)\n",
    "id2word = {v: k for k, v in word2id.items()}\n",
    "vocab_size = len(word2id)\n",
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5cb5dde3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing sentences: 100%|██████████| 132183/132183 [00:01<00:00, 75151.02it/s]\n"
     ]
    }
   ],
   "source": [
    "vocab_size = len(word2id)\n",
    "\n",
    "# List of all tokens for the whole text\n",
    "token_list = []\n",
    "\n",
    "# Process sentences more efficiently\n",
    "for sentence in tqdm(text, desc=\"Processing sentences\"):\n",
    "    token_list.append([word2id[word] for word in sentence.split()])\n",
    "\n",
    "# Now token_list contains the tokenized sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7ed6319f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' Senjō no Valkyria 3 : Unrecorded Chronicles ( Japanese : 戦場のヴァルキュリア3 , lit . Valkyria of the Battlefield 3 ) , commonly referred to as Valkyria Chronicles III outside Japan , is a tactical role @-@ playing video game developed by Sega and Media.Vision for the PlayStation Portable . Released in January 2011 in Japan , it is the third game in the Valkyria series . Employing the same fusion of tactical and real @-@ time gameplay as its predecessors , the story runs parallel to the first game and follows the \" Nameless \" , a penal military unit serving the nation of Gallia during the Second Europan War who perform secret black operations and are pitted against the Imperial unit \" Calamaty Raven \" . \\n',\n",
       " \" The game began development in 2010 , carrying over a large portion of the work done on Valkyria Chronicles II . While it retained the standard features of the series , it also underwent multiple adjustments , such as making the game more forgiving for series newcomers . Character designer Raita Honjou and composer Hitoshi Sakimoto both returned from previous entries , along with Valkyria Chronicles II director Takeshi Ozawa . A large team of writers handled the script . The game 's opening theme was sung by May 'n . \\n\"]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#take a look at sentences\n",
    "sentences[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2330cc70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[135545,\n",
       "  9675,\n",
       "  61793,\n",
       "  194145,\n",
       "  16141,\n",
       "  174428,\n",
       "  48111,\n",
       "  136541,\n",
       "  178867,\n",
       "  16141,\n",
       "  60643,\n",
       "  34713,\n",
       "  61793,\n",
       "  88356,\n",
       "  96108,\n",
       "  131719,\n",
       "  194145,\n",
       "  12811,\n",
       "  61956,\n",
       "  132196,\n",
       "  109341,\n",
       "  188402,\n",
       "  61793,\n",
       "  48111,\n",
       "  154549,\n",
       "  116947,\n",
       "  124779,\n",
       "  44820,\n",
       "  17004,\n",
       "  157958,\n",
       "  3409,\n",
       "  50133,\n",
       "  2978,\n",
       "  3844,\n",
       "  68240,\n",
       "  133914,\n",
       "  22274,\n",
       "  131270,\n",
       "  77750,\n",
       "  104131,\n",
       "  114742,\n",
       "  96108,\n",
       "  8955,\n",
       "  91938,\n",
       "  144431,\n",
       "  92809,\n",
       "  17382,\n",
       "  108510,\n",
       "  92809,\n",
       "  124779,\n",
       "  129240,\n",
       "  44820,\n",
       "  96108,\n",
       "  6538,\n",
       "  68240,\n",
       "  92809,\n",
       "  96108,\n",
       "  61793,\n",
       "  20087,\n",
       "  55585,\n",
       "  96108,\n",
       "  29900,\n",
       "  98463,\n",
       "  88356,\n",
       "  157958,\n",
       "  77750,\n",
       "  120124,\n",
       "  50133,\n",
       "  42082,\n",
       "  114807,\n",
       "  188402,\n",
       "  13215,\n",
       "  197941,\n",
       "  96108,\n",
       "  29083,\n",
       "  146350,\n",
       "  63845,\n",
       "  109341,\n",
       "  96108,\n",
       "  140710,\n",
       "  68240,\n",
       "  77750,\n",
       "  145771,\n",
       "  96108,\n",
       "  89286,\n",
       "  24766,\n",
       "  89286,\n",
       "  17004,\n",
       "  113163,\n",
       "  186601,\n",
       "  43754,\n",
       "  42592,\n",
       "  96108,\n",
       "  25238,\n",
       "  88356,\n",
       "  114221,\n",
       "  136832,\n",
       "  96108,\n",
       "  95902,\n",
       "  3322,\n",
       "  111234,\n",
       "  52738,\n",
       "  32631,\n",
       "  32562,\n",
       "  180387,\n",
       "  80644,\n",
       "  77750,\n",
       "  125311,\n",
       "  78153,\n",
       "  196735,\n",
       "  96108,\n",
       "  177613,\n",
       "  43754,\n",
       "  89286,\n",
       "  100491,\n",
       "  170601,\n",
       "  89286],\n",
       " [96108,\n",
       "  68240,\n",
       "  112802,\n",
       "  133892,\n",
       "  92809,\n",
       "  179797,\n",
       "  73563,\n",
       "  153440,\n",
       "  17004,\n",
       "  156150,\n",
       "  62839,\n",
       "  88356,\n",
       "  96108,\n",
       "  137603,\n",
       "  110855,\n",
       "  154449,\n",
       "  61793,\n",
       "  48111,\n",
       "  45142,\n",
       "  192705,\n",
       "  129240,\n",
       "  83699,\n",
       "  96108,\n",
       "  49884,\n",
       "  45106,\n",
       "  88356,\n",
       "  96108,\n",
       "  20087,\n",
       "  129240,\n",
       "  153886,\n",
       "  87474,\n",
       "  140754,\n",
       "  135930,\n",
       "  25156,\n",
       "  188402,\n",
       "  147053,\n",
       "  96108,\n",
       "  68240,\n",
       "  3172,\n",
       "  7497,\n",
       "  114742,\n",
       "  20087,\n",
       "  141528,\n",
       "  198478,\n",
       "  47326,\n",
       "  41383,\n",
       "  173455,\n",
       "  77750,\n",
       "  13247,\n",
       "  22698,\n",
       "  76899,\n",
       "  16582,\n",
       "  165392,\n",
       "  160035,\n",
       "  140269,\n",
       "  173926,\n",
       "  146145,\n",
       "  142744,\n",
       "  61793,\n",
       "  48111,\n",
       "  45142,\n",
       "  50065,\n",
       "  31710,\n",
       "  170427,\n",
       "  17004,\n",
       "  156150,\n",
       "  28436,\n",
       "  88356,\n",
       "  156630,\n",
       "  163444,\n",
       "  96108,\n",
       "  130687,\n",
       "  96108,\n",
       "  68240,\n",
       "  79631,\n",
       "  120325,\n",
       "  182978,\n",
       "  187024,\n",
       "  8603,\n",
       "  22274,\n",
       "  29845,\n",
       "  190714]]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#take a look at token_list\n",
    "token_list[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "52eb9ae9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "senjō\n",
      "no\n",
      "valkyria\n",
      "3\n",
      ":\n",
      "unrecorded\n",
      "chronicles\n",
      "(\n",
      "japanese\n",
      ":\n",
      "戦場のヴァルキュリア3\n",
      "lit\n",
      "valkyria\n",
      "of\n",
      "the\n",
      "battlefield\n",
      "3\n",
      ")\n",
      "commonly\n",
      "referred\n",
      "to\n",
      "as\n",
      "valkyria\n",
      "chronicles\n",
      "iii\n",
      "outside\n",
      "japan\n",
      "is\n",
      "a\n",
      "tactical\n",
      "role\n",
      "@@\n",
      "playing\n",
      "video\n",
      "game\n",
      "developed\n",
      "by\n",
      "sega\n",
      "and\n",
      "mediavision\n",
      "for\n",
      "the\n",
      "playstation\n",
      "portable\n",
      "released\n",
      "in\n",
      "january\n",
      "2011\n",
      "in\n",
      "japan\n",
      "it\n",
      "is\n",
      "the\n",
      "third\n",
      "game\n",
      "in\n",
      "the\n",
      "valkyria\n",
      "series\n",
      "employing\n",
      "the\n",
      "same\n",
      "fusion\n",
      "of\n",
      "tactical\n",
      "and\n",
      "real\n",
      "@@\n",
      "time\n",
      "gameplay\n",
      "as\n",
      "its\n",
      "predecessors\n",
      "the\n",
      "story\n",
      "runs\n",
      "parallel\n",
      "to\n",
      "the\n",
      "first\n",
      "game\n",
      "and\n",
      "follows\n",
      "the\n",
      "\"\n",
      "nameless\n",
      "\"\n",
      "a\n",
      "penal\n",
      "military\n",
      "unit\n",
      "serving\n",
      "the\n",
      "nation\n",
      "of\n",
      "gallia\n",
      "during\n",
      "the\n",
      "second\n",
      "europan\n",
      "war\n",
      "who\n",
      "perform\n",
      "secret\n",
      "black\n",
      "operations\n",
      "and\n",
      "are\n",
      "pitted\n",
      "against\n",
      "the\n",
      "imperial\n",
      "unit\n",
      "\"\n",
      "calamaty\n",
      "raven\n",
      "\"\n"
     ]
    }
   ],
   "source": [
    "#testing one sentence\n",
    "for tokens in token_list[0]:\n",
    "    print(id2word[tokens])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f0aa4d1",
   "metadata": {},
   "source": [
    "### Data Loader\n",
    "\n",
    "I need to build a custom data loader for pre-training BERT. The data loader constructs training batches that support both of BERT's pre-training objectives:\n",
    "\n",
    "1. **Masked Language Modeling (MLM):** Randomly mask 15% of tokens in each sequence. Among these, 80% are replaced with `[MASK]`, 10% with a random token, and 10% are left unchanged. The model learns to predict the original tokens.\n",
    "\n",
    "2. **Next Sentence Prediction (NSP):** Construct pairs of sentences where 50% are actual consecutive sentences (positive pairs) and 50% are random pairs (negative pairs). The model learns to predict whether the second sentence follows the first.\n",
    "\n",
    "Each training sample is structured as: `[CLS] sentence_A [SEP] sentence_B [SEP]` with corresponding segment embeddings to distinguish the two sentences. All sequences are padded to `max_len` for batching."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3b04d263",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters for data loader\n",
    "batch_size = 6      # Number of samples per batch (half positive, half negative)\n",
    "max_mask   = 5      # Maximum number of masked tokens per sequence\n",
    "max_len    = 512    # Maximum sequence length (padded to this length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7fa5aedf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_batch():\n",
    "    \"\"\"\n",
    "    Create a single training batch for BERT pre-training.\n",
    "    \n",
    "    Each batch contains equal numbers of positive (next sentence) and\n",
    "    negative (random sentence) pairs. For each pair, I apply:\n",
    "    - Token embedding with [CLS] and [SEP] special tokens\n",
    "    - Segment embedding to distinguish sentence A from sentence B  \n",
    "    - Masked Language Modeling (15% masking with 80/10/10 strategy)\n",
    "    - Padding to max_len\n",
    "    \n",
    "    Returns:\n",
    "        list: A batch of [input_ids, segment_ids, masked_tokens, masked_pos, isNext]\n",
    "    \"\"\"\n",
    "    batch = []\n",
    "    positive = negative = 0  # Count to ensure balanced positive/negative pairs\n",
    "\n",
    "    while positive != batch_size / 2 or negative != batch_size / 2:\n",
    "        # Randomly choose two sentence indices\n",
    "        tokens_a_index, tokens_b_index = randrange(len(sentences)), randrange(len(sentences))\n",
    "        # Retrieve the corresponding token sequences\n",
    "        tokens_a, tokens_b = token_list[tokens_a_index], token_list[tokens_b_index]\n",
    "\n",
    "        # Skip if combined length exceeds max_len (accounting for [CLS] and two [SEP] tokens)\n",
    "        if len(tokens_a) + len(tokens_b) + 3 > max_len:\n",
    "            continue\n",
    "\n",
    "        # 1. Token embedding: prepend [CLS], insert [SEP] between sentences, append [SEP]\n",
    "        input_ids = [word2id['[CLS]']] + tokens_a + [word2id['[SEP]']] + tokens_b + [word2id['[SEP]']]\n",
    "\n",
    "        # 2. Segment embedding: 0 for sentence A (including [CLS] and first [SEP]), 1 for sentence B\n",
    "        segment_ids = [0] * (1 + len(tokens_a) + 1) + [1] * (len(tokens_b) + 1)\n",
    "\n",
    "        # 3. Masked Language Modeling\n",
    "        # Mask 15% of tokens, but at least 1 and at most max_mask\n",
    "        n_pred = min(max_mask, max(1, int(round(len(input_ids) * 0.15))))\n",
    "        # Get candidate positions (exclude [CLS] and [SEP] tokens)\n",
    "        cand_masked_pos = [i for i, token in enumerate(input_ids)\n",
    "                          if token != word2id['[CLS]'] and token != word2id['[SEP]']]\n",
    "        shuffle(cand_masked_pos)\n",
    "        \n",
    "        masked_tokens, masked_pos = [], []\n",
    "        for pos in cand_masked_pos[:n_pred]:\n",
    "            masked_pos.append(pos)          # Remember the position\n",
    "            masked_tokens.append(input_ids[pos])  # Remember the original token\n",
    "            # Apply masking strategy: 80% [MASK], 10% random token, 10% unchanged\n",
    "            if random() < 0.1:       # 10% - replace with random token\n",
    "                index = randint(0, vocab_size - 1)\n",
    "                input_ids[pos] = word2id[id2word[index]]\n",
    "            elif random() < 0.9:     # 80% - replace with [MASK]\n",
    "                input_ids[pos] = word2id['[MASK]']\n",
    "            # else: 10% - keep original token (do nothing)\n",
    "\n",
    "        # 4. Pad input_ids and segment_ids to max_len\n",
    "        n_pad = max_len - len(input_ids)\n",
    "        input_ids.extend([0] * n_pad)\n",
    "        segment_ids.extend([0] * n_pad)\n",
    "\n",
    "        # Pad masked_tokens and masked_pos to max_mask length\n",
    "        if max_mask > n_pred:\n",
    "            n_pad = max_mask - n_pred\n",
    "            masked_tokens.extend([0] * n_pad)\n",
    "            masked_pos.extend([0] * n_pad)\n",
    "\n",
    "        # Check if sentence B actually follows sentence A (Next Sentence Prediction)\n",
    "        if tokens_a_index + 1 == tokens_b_index and positive < batch_size / 2:\n",
    "            batch.append([input_ids, segment_ids, masked_tokens, masked_pos, True])  # IsNext\n",
    "            positive += 1\n",
    "        elif tokens_a_index + 1 != tokens_b_index and negative < batch_size / 2:\n",
    "            batch.append([input_ids, segment_ids, masked_tokens, masked_pos, False])  # NotNext\n",
    "            negative += 1\n",
    "\n",
    "    return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dbecafe1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch size: 6\n",
      "input_ids shape:     torch.Size([6, 512])\n",
      "segment_ids shape:   torch.Size([6, 512])\n",
      "masked_tokens shape: torch.Size([6, 5])\n",
      "masked_pos shape:    torch.Size([6, 5])\n",
      "isNext shape:        torch.Size([6])\n"
     ]
    }
   ],
   "source": [
    "# Test creating a batch and inspect shapes\n",
    "batch = make_batch()\n",
    "print(f\"Batch size: {len(batch)}\")\n",
    "\n",
    "# Deconstruct batch into tensors using map and zip\n",
    "input_ids, segment_ids, masked_tokens, masked_pos, isNext = map(torch.LongTensor, zip(*batch))\n",
    "print(f\"input_ids shape:     {input_ids.shape}\")\n",
    "print(f\"segment_ids shape:   {segment_ids.shape}\")\n",
    "print(f\"masked_tokens shape: {masked_tokens.shape}\")\n",
    "print(f\"masked_pos shape:    {masked_pos.shape}\")\n",
    "print(f\"isNext shape:        {isNext.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecc943b1",
   "metadata": {},
   "source": [
    "### BERT Model Architecture\n",
    "\n",
    "I implement BERT from scratch following the original paper. The model consists of the following components:\n",
    "\n",
    "1. **Embedding Layer:** Combines three embeddings - token embedding, positional embedding, and segment embedding - followed by Layer Normalization.\n",
    "\n",
    "2. **Scaled Dot-Product Attention:** Computes attention weights as $\\text{Attention}(Q, K, V) = \\text{softmax}\\left(\\frac{QK^T}{\\sqrt{d_k}}\\right)V$ with padding mask support.\n",
    "\n",
    "3. **Multi-Head Attention:** Projects queries, keys, and values into multiple heads, applies scaled dot-product attention in parallel, then concatenates and projects back.\n",
    "\n",
    "4. **Position-wise Feed-Forward Network:** Two linear transformations with GELU activation: $\\text{FFN}(x) = W_2 \\cdot \\text{GELU}(W_1 x + b_1) + b_2$.\n",
    "\n",
    "5. **Encoder Layer:** Combines multi-head attention and feed-forward network with residual connections and layer normalization.\n",
    "\n",
    "6. **Full BERT Model:** Stacks multiple encoder layers and adds two prediction heads for MLM and NSP tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e4d4824a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BERT Configuration:\n",
      "  Layers: 6, Heads: 8, d_model: 768\n",
      "  d_ff: 3072, d_k: 64, d_v: 64\n",
      "  Vocab size: 199405, Max length: 512\n"
     ]
    }
   ],
   "source": [
    "# ==================== BERT Model Hyperparameters ====================\n",
    "n_layers   = 6     # Number of Transformer encoder layers\n",
    "n_heads    = 8     # Number of attention heads in Multi-Head Attention\n",
    "d_model    = 768   # Hidden size / embedding dimension\n",
    "d_ff       = d_model * 4  # Feed-forward intermediate dimension (4 * d_model = 3072)\n",
    "d_k = d_v  = 64    # Dimension of each attention head for keys/queries and values\n",
    "n_segments = 2     # Number of segment types (sentence A = 0, sentence B = 1)\n",
    "\n",
    "print(f\"BERT Configuration:\")\n",
    "print(f\"  Layers: {n_layers}, Heads: {n_heads}, d_model: {d_model}\")\n",
    "print(f\"  d_ff: {d_ff}, d_k: {d_k}, d_v: {d_v}\")\n",
    "print(f\"  Vocab size: {vocab_size}, Max length: {max_len}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "39977159",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Embedding(nn.Module):\n",
    "    \"\"\"\n",
    "    BERT Embedding Layer.\n",
    "    \n",
    "    Combines three types of embeddings:\n",
    "    - Token embedding: maps vocabulary indices to dense vectors\n",
    "    - Position embedding: encodes the position of each token in the sequence\n",
    "    - Segment embedding: distinguishes between sentence A and sentence B\n",
    "    \n",
    "    All three are summed and passed through Layer Normalization.\n",
    "    \"\"\"\n",
    "    def __init__(self, vocab_size, max_len, n_segments, d_model, device):\n",
    "        super(Embedding, self).__init__()\n",
    "        self.tok_embed = nn.Embedding(vocab_size, d_model)   # Token embedding\n",
    "        self.pos_embed = nn.Embedding(max_len, d_model)      # Position embedding\n",
    "        self.seg_embed = nn.Embedding(n_segments, d_model)   # Segment (token type) embedding\n",
    "        self.norm = nn.LayerNorm(d_model)\n",
    "        self.device = device\n",
    "\n",
    "    def forward(self, x, seg):\n",
    "        # x: (batch_size, seq_len), seg: (batch_size, seq_len)\n",
    "        seq_len = x.size(1)\n",
    "        # Create position indices [0, 1, 2, ..., seq_len-1]\n",
    "        pos = torch.arange(seq_len, dtype=torch.long).to(self.device)\n",
    "        pos = pos.unsqueeze(0).expand_as(x)  # (seq_len,) -> (batch_size, seq_len)\n",
    "        # Sum all three embeddings and normalize\n",
    "        embedding = self.tok_embed(x) + self.pos_embed(pos) + self.seg_embed(seg)\n",
    "        return self.norm(embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fab9e7c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_attn_pad_mask(seq_q, seq_k, device):\n",
    "    \"\"\"\n",
    "    Create attention padding mask.\n",
    "    \n",
    "    Generates a boolean mask where True indicates padding positions (token id = 0).\n",
    "    This prevents the attention mechanism from attending to padding tokens.\n",
    "    \n",
    "    Args:\n",
    "        seq_q: Query sequence tensor (batch_size, len_q)\n",
    "        seq_k: Key sequence tensor (batch_size, len_k)\n",
    "        device: Device to place the mask on\n",
    "        \n",
    "    Returns:\n",
    "        Tensor of shape (batch_size, len_q, len_k) with True at padding positions\n",
    "    \"\"\"\n",
    "    batch_size, len_q = seq_q.size()\n",
    "    batch_size, len_k = seq_k.size()\n",
    "    # eq(0) marks PAD token positions as True\n",
    "    pad_attn_mask = seq_k.data.eq(0).unsqueeze(1).to(device)  # (batch_size, 1, len_k)\n",
    "    return pad_attn_mask.expand(batch_size, len_q, len_k)      # (batch_size, len_q, len_k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1843617c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ScaledDotProductAttention(nn.Module):\n",
    "    \"\"\"\n",
    "    Scaled Dot-Product Attention mechanism.\n",
    "    \n",
    "    Computes attention as: Attention(Q, K, V) = softmax(QK^T / sqrt(d_k)) * V\n",
    "    Applies a mask to prevent attending to padding positions.\n",
    "    \"\"\"\n",
    "    def __init__(self, d_k, device):\n",
    "        super(ScaledDotProductAttention, self).__init__()\n",
    "        self.scale = torch.sqrt(torch.FloatTensor([d_k])).to(device)\n",
    "\n",
    "    def forward(self, Q, K, V, attn_mask):\n",
    "        # Q, K, V: (batch_size, n_heads, seq_len, d_k)\n",
    "        # Compute attention scores\n",
    "        scores = torch.matmul(Q, K.transpose(-1, -2)) / self.scale  # (batch_size, n_heads, len_q, len_k)\n",
    "        # Apply mask: fill masked positions with -1e9 (effectively -infinity after softmax)\n",
    "        scores.masked_fill_(attn_mask, -1e9)\n",
    "        # Compute attention weights via softmax\n",
    "        attn = nn.Softmax(dim=-1)(scores)\n",
    "        # Compute weighted sum of values\n",
    "        context = torch.matmul(attn, V)\n",
    "        return context, attn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a3c43b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    \"\"\"\n",
    "    Multi-Head Attention mechanism.\n",
    "    \n",
    "    Projects input into multiple attention heads, applies scaled dot-product\n",
    "    attention in parallel, concatenates results, and projects back to d_model.\n",
    "    Includes residual connection and layer normalization.\n",
    "    \"\"\"\n",
    "    def __init__(self, n_heads, d_model, d_k, device):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        self.n_heads = n_heads\n",
    "        self.d_model = d_model\n",
    "        self.d_k = d_k\n",
    "        self.d_v = d_k\n",
    "        # Linear projections for Q, K, V\n",
    "        self.W_Q = nn.Linear(d_model, d_k * n_heads)\n",
    "        self.W_K = nn.Linear(d_model, d_k * n_heads)\n",
    "        self.W_V = nn.Linear(d_model, self.d_v * n_heads)\n",
    "        # Output projection\n",
    "        self.fc = nn.Linear(n_heads * self.d_v, d_model)\n",
    "        self.layer_norm = nn.LayerNorm(d_model)\n",
    "        self.device = device\n",
    "\n",
    "    def forward(self, Q, K, V, attn_mask):\n",
    "        # Q, K, V: (batch_size, seq_len, d_model)\n",
    "        residual, batch_size = Q, Q.size(0)\n",
    "        \n",
    "        # Project and reshape: (batch_size, seq_len, d_model) -> (batch_size, n_heads, seq_len, d_k)\n",
    "        q_s = self.W_Q(Q).view(batch_size, -1, self.n_heads, self.d_k).transpose(1, 2)\n",
    "        k_s = self.W_K(K).view(batch_size, -1, self.n_heads, self.d_k).transpose(1, 2)\n",
    "        v_s = self.W_V(V).view(batch_size, -1, self.n_heads, self.d_v).transpose(1, 2)\n",
    "\n",
    "        # Expand attention mask for all heads: (batch_size, n_heads, len_q, len_k)\n",
    "        attn_mask = attn_mask.unsqueeze(1).repeat(1, self.n_heads, 1, 1)\n",
    "\n",
    "        # Apply scaled dot-product attention\n",
    "        context, attn = ScaledDotProductAttention(self.d_k, self.device)(q_s, k_s, v_s, attn_mask)\n",
    "        \n",
    "        # Concatenate heads: (batch_size, seq_len, n_heads * d_v)\n",
    "        context = context.transpose(1, 2).contiguous().view(batch_size, -1, self.n_heads * self.d_v)\n",
    "        \n",
    "        # Final linear projection\n",
    "        output = self.fc(context)\n",
    "        \n",
    "        # Residual connection + layer normalization\n",
    "        return self.layer_norm(output + residual), attn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "aed1641e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PoswiseFeedForwardNet(nn.Module):\n",
    "    \"\"\"\n",
    "    Position-wise Feed-Forward Network.\n",
    "    \n",
    "    Applies two linear transformations with a GELU activation in between:\n",
    "    FFN(x) = W2 * GELU(W1 * x + b1) + b2\n",
    "    \n",
    "    This expands the representation to d_ff dimensions and then compresses back to d_model.\n",
    "    \"\"\"\n",
    "    def __init__(self, d_model, d_ff):\n",
    "        super(PoswiseFeedForwardNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(d_model, d_ff)   # Expansion layer\n",
    "        self.fc2 = nn.Linear(d_ff, d_model)   # Compression layer\n",
    "\n",
    "    def forward(self, x):\n",
    "        # (batch_size, seq_len, d_model) -> (batch_size, seq_len, d_ff) -> (batch_size, seq_len, d_model)\n",
    "        return self.fc2(F.gelu(self.fc1(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3ed2750d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLayer(nn.Module):\n",
    "    \"\"\"\n",
    "    Single Transformer Encoder Layer.\n",
    "    \n",
    "    Consists of:\n",
    "    1. Multi-Head Self-Attention with residual connection and layer norm\n",
    "    2. Position-wise Feed-Forward Network\n",
    "    \"\"\"\n",
    "    def __init__(self, n_heads, d_model, d_ff, d_k, device):\n",
    "        super(EncoderLayer, self).__init__()\n",
    "        self.enc_self_attn = MultiHeadAttention(n_heads, d_model, d_k, device)\n",
    "        self.pos_ffn = PoswiseFeedForwardNet(d_model, d_ff)\n",
    "\n",
    "    def forward(self, enc_inputs, enc_self_attn_mask):\n",
    "        # Self-attention: Q=K=V=enc_inputs\n",
    "        enc_outputs, attn = self.enc_self_attn(enc_inputs, enc_inputs, enc_inputs, enc_self_attn_mask)\n",
    "        # Feed-forward network\n",
    "        enc_outputs = self.pos_ffn(enc_outputs)  # (batch_size, seq_len, d_model)\n",
    "        return enc_outputs, attn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6ddc3c8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BERT(nn.Module):\n",
    "    \"\"\"\n",
    "    Bidirectional Encoder Representations from Transformers (BERT).\n",
    "    \n",
    "    This model implements the full BERT architecture with two pre-training objectives:\n",
    "    1. Masked Language Model (MLM): Predicts masked tokens in the input sequence\n",
    "    2. Next Sentence Prediction (NSP): Predicts whether sentence B follows sentence A\n",
    "    \n",
    "    The model also provides a method to extract the last hidden state for downstream tasks\n",
    "    like Sentence-BERT.\n",
    "    \n",
    "    Architecture:\n",
    "    - Embedding layer (token + position + segment)\n",
    "    - Stack of Transformer encoder layers\n",
    "    - MLM head (linear + GELU + layer norm + decoder)\n",
    "    - NSP head (tanh activation + classifier)\n",
    "    \"\"\"\n",
    "    def __init__(self, n_layers, n_heads, d_model, d_ff, d_k, n_segments, vocab_size, max_len, device):\n",
    "        super(BERT, self).__init__()\n",
    "        # Store hyperparameters for later reference (useful when saving/loading)\n",
    "        self.params = {\n",
    "            'n_layers': n_layers, 'n_heads': n_heads, 'd_model': d_model,\n",
    "            'd_ff': d_ff, 'd_k': d_k, 'n_segments': n_segments,\n",
    "            'vocab_size': vocab_size, 'max_len': max_len\n",
    "        }\n",
    "        \n",
    "        # Embedding layer\n",
    "        self.embedding = Embedding(vocab_size, max_len, n_segments, d_model, device)\n",
    "        \n",
    "        # Stack of Transformer encoder layers\n",
    "        self.layers = nn.ModuleList([\n",
    "            EncoderLayer(n_heads, d_model, d_ff, d_k, device) for _ in range(n_layers)\n",
    "        ])\n",
    "        \n",
    "        # NSP head: [CLS] token -> tanh -> binary classifier\n",
    "        self.fc = nn.Linear(d_model, d_model)\n",
    "        self.activ = nn.Tanh()\n",
    "        self.classifier = nn.Linear(d_model, 2)  # IsNext / NotNext\n",
    "        \n",
    "        # MLM head: masked positions -> linear -> GELU -> layer norm -> decoder\n",
    "        self.linear = nn.Linear(d_model, d_model)\n",
    "        self.norm = nn.LayerNorm(d_model)\n",
    "        \n",
    "        # Decoder shares weights with the token embedding layer (weight tying)\n",
    "        embed_weight = self.embedding.tok_embed.weight\n",
    "        n_vocab, n_dim = embed_weight.size()\n",
    "        self.decoder = nn.Linear(n_dim, n_vocab, bias=False)\n",
    "        self.decoder.weight = embed_weight\n",
    "        self.decoder_bias = nn.Parameter(torch.zeros(n_vocab))\n",
    "        \n",
    "        self.device = device\n",
    "\n",
    "    def forward(self, input_ids, segment_ids, masked_pos):\n",
    "        \"\"\"\n",
    "        Forward pass for BERT pre-training.\n",
    "        \n",
    "        Args:\n",
    "            input_ids: Token indices (batch_size, seq_len)\n",
    "            segment_ids: Segment indices (batch_size, seq_len)\n",
    "            masked_pos: Positions of masked tokens (batch_size, max_mask)\n",
    "            \n",
    "        Returns:\n",
    "            logits_lm: MLM logits (batch_size, max_mask, vocab_size)\n",
    "            logits_nsp: NSP logits (batch_size, 2)\n",
    "        \"\"\"\n",
    "        # Get contextualized embeddings from the encoder stack\n",
    "        output = self.embedding(input_ids, segment_ids)\n",
    "        enc_self_attn_mask = get_attn_pad_mask(input_ids, input_ids, self.device)\n",
    "        for layer in self.layers:\n",
    "            output, enc_self_attn = layer(output, enc_self_attn_mask)\n",
    "        # output: (batch_size, seq_len, d_model)\n",
    "        \n",
    "        # 1. Next Sentence Prediction: use the [CLS] token representation (position 0)\n",
    "        h_pooled = self.activ(self.fc(output[:, 0]))   # (batch_size, d_model)\n",
    "        logits_nsp = self.classifier(h_pooled)          # (batch_size, 2)\n",
    "\n",
    "        # 2. Masked Language Model: extract representations at masked positions\n",
    "        masked_pos = masked_pos[:, :, None].expand(-1, -1, output.size(-1))  # (batch_size, max_mask, d_model)\n",
    "        h_masked = torch.gather(output, 1, masked_pos)  # (batch_size, max_mask, d_model)\n",
    "        h_masked = self.norm(F.gelu(self.linear(h_masked)))\n",
    "        logits_lm = self.decoder(h_masked) + self.decoder_bias  # (batch_size, max_mask, vocab_size)\n",
    "\n",
    "        return logits_lm, logits_nsp\n",
    "\n",
    "    def get_last_hidden_state(self, input_ids, segment_ids):\n",
    "        \"\"\"\n",
    "        Extract the last hidden state from the encoder (used for downstream tasks like S-BERT).\n",
    "        \n",
    "        Args:\n",
    "            input_ids: Token indices (batch_size, seq_len)\n",
    "            segment_ids: Segment indices (batch_size, seq_len)\n",
    "            \n",
    "        Returns:\n",
    "            output: Last hidden state (batch_size, seq_len, d_model)\n",
    "        \"\"\"\n",
    "        output = self.embedding(input_ids, segment_ids)\n",
    "        enc_self_attn_mask = get_attn_pad_mask(input_ids, input_ids, self.device)\n",
    "        for layer in self.layers:\n",
    "            output, enc_self_attn = layer(output, enc_self_attn_mask)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77ec2de3",
   "metadata": {},
   "source": [
    "### Training BERT\n",
    "\n",
    "I now train the BERT model using the two pre-training objectives:\n",
    "- **Masked Language Model (MLM):** Cross-entropy loss between predicted and actual masked tokens\n",
    "- **Next Sentence Prediction (NSP):** Cross-entropy loss for binary classification (IsNext / NotNext)\n",
    "\n",
    "The total loss is the sum of both objectives: $\\mathcal{L} = \\mathcal{L}_{MLM} + \\mathcal{L}_{NSP}$\n",
    "\n",
    "I use the Adam optimizer with a learning rate of 0.0001. Training is done for 100 epochs, where each epoch creates a new random batch with fresh masking patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c8067705",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total parameters: 192,717,807\n",
      "Trainable parameters: 192,717,807\n"
     ]
    }
   ],
   "source": [
    "# Initialize the BERT model and move to GPU\n",
    "num_epoch = 100\n",
    "\n",
    "model = BERT(\n",
    "    n_layers=n_layers,\n",
    "    n_heads=n_heads,\n",
    "    d_model=d_model,\n",
    "    d_ff=d_ff,\n",
    "    d_k=d_k,\n",
    "    n_segments=n_segments,\n",
    "    vocab_size=vocab_size,\n",
    "    max_len=max_len,\n",
    "    device=device\n",
    ").to(device)\n",
    "\n",
    "# Loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "\n",
    "# Print model summary\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"Total parameters: {total_params:,}\")\n",
    "print(f\"Trainable parameters: {trainable_params:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3b422ba",
   "metadata": {},
   "source": [
    "### BERT Model Summary\n",
    "\n",
    "I display the full model architecture and a detailed parameter breakdown to verify the model structure before training. The table below summarizes all hyperparameters used for pre-training.\n",
    "\n",
    "| Component | Detail |\n",
    "|---|---|\n",
    "| **Encoder Layers** | 6 |\n",
    "| **Attention Heads** | 8 |\n",
    "| **Hidden Size (d_model)** | 768 |\n",
    "| **Feed-Forward Size (d_ff)** | 3072 (4 × d_model) |\n",
    "| **Head Dimension (d_k = d_v)** | 64 |\n",
    "| **Vocabulary Size** | Built from WikiText-103 |\n",
    "| **Max Sequence Length** | 512 |\n",
    "| **Pre-training Objectives** | MLM + NSP |\n",
    "| **Optimizer** | Adam (lr = 1e-4) |\n",
    "| **Epochs** | 100 |\n",
    "| **Batch Size** | 6 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c0f2e4d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "BERT Pre-training Model Architecture\n",
      "======================================================================\n",
      "BERT(\n",
      "  (embedding): Embedding(\n",
      "    (tok_embed): Embedding(199405, 768)\n",
      "    (pos_embed): Embedding(512, 768)\n",
      "    (seg_embed): Embedding(2, 768)\n",
      "    (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      "  (layers): ModuleList(\n",
      "    (0-5): 6 x EncoderLayer(\n",
      "      (enc_self_attn): MultiHeadAttention(\n",
      "        (W_Q): Linear(in_features=768, out_features=512, bias=True)\n",
      "        (W_K): Linear(in_features=768, out_features=512, bias=True)\n",
      "        (W_V): Linear(in_features=768, out_features=512, bias=True)\n",
      "        (fc): Linear(in_features=512, out_features=768, bias=True)\n",
      "        (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (pos_ffn): PoswiseFeedForwardNet(\n",
      "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (fc): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (activ): Tanh()\n",
      "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
      "  (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  (decoder): Linear(in_features=768, out_features=199405, bias=False)\n",
      ")\n",
      "\n",
      "======================================================================\n",
      "Layer-wise Parameter Count\n",
      "======================================================================\n",
      "  decoder_bias        :      199,405 params\n",
      "  embedding           :  153,539,328 params\n",
      "  layers              :   37,794,816 params\n",
      "  fc                  :      590,592 params\n",
      "  classifier          :        1,538 params\n",
      "  linear              :      590,592 params\n",
      "  norm                :        1,536 params\n",
      "\n",
      "  Total               :  192,717,807 params\n",
      "  Trainable           :  192,717,807 params\n",
      "  Non-trainable       :            0 params\n",
      "\n",
      "======================================================================\n",
      "Hyperparameters Summary\n",
      "======================================================================\n",
      "  n_layers            : 6\n",
      "  n_heads             : 8\n",
      "  d_model             : 768\n",
      "  d_ff                : 3072\n",
      "  d_k / d_v           : 64\n",
      "  n_segments          : 2\n",
      "  vocab_size          : 199405\n",
      "  max_len             : 512\n",
      "  optimizer           : Adam\n",
      "  learning_rate       : 0.0001\n",
      "  epochs              : 100\n",
      "  batch_size          : 6\n",
      "  max_mask            : 5\n",
      "  pre-training tasks  : MLM + NSP\n"
     ]
    }
   ],
   "source": [
    "# ==================== BERT Model Structure & Parameters ====================\n",
    "print(\"=\" * 70)\n",
    "print(\"BERT Pre-training Model Architecture\")\n",
    "print(\"=\" * 70)\n",
    "print(model)\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"Layer-wise Parameter Count\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Detailed parameter breakdown\n",
    "param_summary = {}\n",
    "for name, param in model.named_parameters():\n",
    "    layer_group = name.split('.')[0]  # Top-level module name\n",
    "    count = param.numel()\n",
    "    param_summary[layer_group] = param_summary.get(layer_group, 0) + count\n",
    "\n",
    "for group, count in param_summary.items():\n",
    "    print(f\"  {group:20s}: {count:>12,} params\")\n",
    "\n",
    "total = sum(p.numel() for p in model.parameters())\n",
    "trainable = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"\\n  {'Total':20s}: {total:>12,} params\")\n",
    "print(f\"  {'Trainable':20s}: {trainable:>12,} params\")\n",
    "print(f\"  {'Non-trainable':20s}: {total - trainable:>12,} params\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"Hyperparameters Summary\")\n",
    "print(\"=\" * 70)\n",
    "hyperparams = {\n",
    "    \"n_layers\": n_layers, \"n_heads\": n_heads, \"d_model\": d_model,\n",
    "    \"d_ff\": d_ff, \"d_k / d_v\": d_k, \"n_segments\": n_segments,\n",
    "    \"vocab_size\": vocab_size, \"max_len\": max_len,\n",
    "    \"optimizer\": \"Adam\", \"learning_rate\": 0.0001,\n",
    "    \"epochs\": num_epoch, \"batch_size\": batch_size,\n",
    "    \"max_mask\": max_mask, \"pre-training tasks\": \"MLM + NSP\",\n",
    "}\n",
    "for k, v in hyperparams.items():\n",
    "    print(f\"  {k:20s}: {v}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a7b0f696",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pre-training BERT:  10%|█         | 10/100 [02:03<20:58, 13.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  10/100 | Loss: 99.708092 | MLM Loss: 99.014351 | NSP Loss: 0.693744\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pre-training BERT:  20%|██        | 20/100 [04:03<18:57, 14.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  20/100 | Loss: 97.092819 | MLM Loss: 96.399139 | NSP Loss: 0.693678\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pre-training BERT:  30%|███       | 30/100 [06:54<18:08, 15.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  30/100 | Loss: 82.626106 | MLM Loss: 81.932930 | NSP Loss: 0.693176\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pre-training BERT:  40%|████      | 40/100 [09:09<10:08, 10.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  40/100 | Loss: 76.424911 | MLM Loss: 75.731644 | NSP Loss: 0.693271\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pre-training BERT:  50%|█████     | 50/100 [11:32<08:35, 10.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  50/100 | Loss: 70.669983 | MLM Loss: 69.976837 | NSP Loss: 0.693144\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pre-training BERT:  60%|██████    | 60/100 [13:42<06:57, 10.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  60/100 | Loss: 73.599632 | MLM Loss: 72.906494 | NSP Loss: 0.693137\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pre-training BERT:  70%|███████   | 70/100 [16:06<04:10,  8.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  70/100 | Loss: 56.410080 | MLM Loss: 55.716854 | NSP Loss: 0.693227\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pre-training BERT:  80%|████████  | 80/100 [20:17<09:38, 28.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  80/100 | Loss: 62.496159 | MLM Loss: 61.802979 | NSP Loss: 0.693180\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pre-training BERT:  90%|█████████ | 90/100 [23:44<02:49, 16.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  90/100 | Loss: 55.269810 | MLM Loss: 54.576572 | NSP Loss: 0.693237\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pre-training BERT: 100%|██████████| 100/100 [26:19<00:00, 15.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100/100 | Loss: 62.228508 | MLM Loss: 61.535118 | NSP Loss: 0.693388\n",
      "\n",
      "Training complete! Final loss: 62.228508\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# ==================== BERT Pre-training Loop ====================\n",
    "for epoch in tqdm(range(num_epoch), desc=\"Pre-training BERT\"):\n",
    "    # Create a fresh batch each epoch (different masking patterns and sentence pairs)\n",
    "    batch = make_batch()\n",
    "    input_ids, segment_ids, masked_tokens, masked_pos, isNext = map(torch.LongTensor, zip(*batch))\n",
    "\n",
    "    # Move all tensors to the active device (GPU)\n",
    "    input_ids = input_ids.to(device)\n",
    "    segment_ids = segment_ids.to(device)\n",
    "    masked_tokens = masked_tokens.to(device)\n",
    "    masked_pos = masked_pos.to(device)\n",
    "    isNext = isNext.to(device)\n",
    "\n",
    "    # Zero gradients\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # Forward pass\n",
    "    logits_lm, logits_nsp = model(input_ids, segment_ids, masked_pos)\n",
    "    # logits_lm: (batch_size, max_mask, vocab_size)\n",
    "    # logits_nsp: (batch_size, 2)\n",
    "\n",
    "    # 1. MLM loss: compare predicted tokens with actual masked tokens\n",
    "    # logits_lm.transpose(1,2): (batch_size, vocab_size, max_mask)\n",
    "    # masked_tokens: (batch_size, max_mask)\n",
    "    loss_lm = criterion(logits_lm.transpose(1, 2), masked_tokens)\n",
    "    loss_lm = loss_lm.float().mean()\n",
    "\n",
    "    # 2. NSP loss: binary classification (IsNext / NotNext)\n",
    "    loss_nsp = criterion(logits_nsp, isNext)\n",
    "\n",
    "    # 3. Combined loss\n",
    "    loss = loss_lm + loss_nsp\n",
    "\n",
    "    # Backward pass and optimization\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # Print progress every 10 epochs\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print(f\"Epoch {epoch + 1:3d}/{num_epoch} | Loss: {loss.item():.6f} | MLM Loss: {loss_lm.item():.6f} | NSP Loss: {loss_nsp.item():.6f}\")\n",
    "\n",
    "print(f\"\\nTraining complete! Final loss: {loss.item():.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "814e8a59",
   "metadata": {},
   "source": [
    "### BERT Pre-training Inference Test\n",
    "\n",
    "I verify that the pre-trained BERT model can correctly predict masked tokens and next sentence relationships. I pick one sample from the batch and check:\n",
    "- Whether the predicted masked tokens match the original tokens\n",
    "- Whether the Next Sentence Prediction is correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "096ba773",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input sequence:\n",
      "['[CLS]', 'a', 'mimed', 'stage', '[MASK]', 'thunderbirds', ':', 'fab', 'has', 'grandidier', 'internationally', 'and', 'popularised', 'a', 'staccato', 'style', 'of', 'movement', 'known', 'colloquially', 'as', 'the', '\"', 'thunderbirds', 'walk', '\"', 'the', 'production', 'has', 'periodically', 'been', 'revived', 'as', 'thunderbirds', ':', 'fab', '–', 'the', 'next', 'generation', '[SEP]', 'richard', 'barre', '(', 'c', '1130', '–', 'c', '1202', ')', 'was', 'a', 'medieval', 'english', 'justice', 'clergyman', 'and', 'scholar', 'he', 'was', 'educated', 'at', 'the', 'law', 'school', 'of', 'bologna', 'and', 'entered', 'royal', 'service', 'under', 'king', 'henry', 'ii', 'of', 'england', 'later', 'working', 'for', 'henry', \"'s\", 'son', 'and', 'successor', 'richard', 'i', 'he', 'was', 'also', 'briefly', 'in', 'the', 'household', 'of', 'henry', \"'s\", 'son', 'henry', 'the', 'young', 'king', 'barre', 'served', 'the', 'elder', 'henry', '[MASK]', 'a', '[MASK]', 'and', 'was', 'involved', 'in', 'a', 'minor', '[MASK]', 'with', 'the', 'king', \"'s\", 'quarrel', 'with', 'thomas', 'becket', 'which', 'earned', 'barre', 'a', 'condemnation', 'from', 'becket', 'after', 'king', 'henry', \"'s\", 'death', 'barre', 'became', 'a', 'royal', 'justice', 'during', 'richard', \"'s\", 'reign', 'and', 'was', 'one', 'of', 'the', 'main', 'judges', 'in', 'the', 'period', 'from', '1194', 'to', '1199', 'after', 'disagreeing', 'with', 'him', 'earlier', 'in', 'his', 'career', 'barre', 'was', 'discharged', 'from', 'his', 'judgeship', 'during', 'john', \"'s\", 'reign', 'as', 'king', 'barre', 'was', 'also', 'archdeacon', 'of', 'ely', 'and', 'the', 'author', 'of', 'a', 'work', 'of', 'biblical', 'extracts', 'dedicated', 'to', 'one', 'of', 'his', 'patrons', 'william', 'longchamp', 'the', 'bishop', 'of', 'ely', 'and', 'chancellor', 'of', 'england', '[SEP]']\n",
      "\n",
      "Masked tokens (ground truth): ['toured', 'as', 'diplomat', 'show', 'way']\n",
      "Predicted masked tokens:      ['mula', 'mula', 'mula', 'mula', 'mula']\n",
      "\n",
      "Actual isNext:    False\n",
      "Predicted isNext: True\n"
     ]
    }
   ],
   "source": [
    "# ==================== Inference Test ====================\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    # Take the third sample from the last batch for testing\n",
    "    test_input_ids, test_segment_ids, test_masked_tokens, test_masked_pos, test_isNext = map(\n",
    "        torch.LongTensor, zip(batch[2])\n",
    "    )\n",
    "    \n",
    "    # Print the input sequence (excluding padding)\n",
    "    print(\"Input sequence:\")\n",
    "    print([id2word[w.item()] for w in test_input_ids[0] if id2word[w.item()] != '[PAD]'])\n",
    "    \n",
    "    # Move tensors to device\n",
    "    test_input_ids = test_input_ids.to(device)\n",
    "    test_segment_ids = test_segment_ids.to(device)\n",
    "    test_masked_tokens = test_masked_tokens.to(device)\n",
    "    test_masked_pos = test_masked_pos.to(device)\n",
    "    test_isNext = test_isNext.to(device)\n",
    "    \n",
    "    # Forward pass\n",
    "    logits_lm, logits_nsp = model(test_input_ids, test_segment_ids, test_masked_pos)\n",
    "    \n",
    "    # Predict masked tokens: get the token with highest probability\n",
    "    predicted_tokens = logits_lm.data.cpu().max(2)[1][0].data.numpy()\n",
    "    \n",
    "    print(f\"\\nMasked tokens (ground truth): {[id2word[pos.item()] for pos in test_masked_tokens[0]]}\")\n",
    "    print(f\"Predicted masked tokens:      {[id2word[pos.item()] for pos in predicted_tokens]}\")\n",
    "    \n",
    "    # Predict NSP\n",
    "    predicted_nsp = logits_nsp.cpu().data.max(1)[1][0].data.numpy()\n",
    "    print(f\"\\nActual isNext:    {True if test_isNext else False}\")\n",
    "    print(f\"Predicted isNext: {True if predicted_nsp else False}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a4a6452",
   "metadata": {},
   "source": [
    "### Save Pre-trained BERT Model\n",
    "\n",
    "I save the pre-trained BERT model weights along with the vocabulary mappings and model hyperparameters. These will be loaded in Task 2 for fine-tuning with Sentence-BERT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b1a6eb50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to model/bert_pretrained.pth\n",
      "Vocabulary saved to model/vocab.pkl\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "# Create model directory if it doesn't exist\n",
    "os.makedirs('model', exist_ok=True)\n",
    "\n",
    "# Save the model state dict and hyperparameters\n",
    "torch.save({\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'model_params': model.params,\n",
    "}, 'model/bert_pretrained.pth')\n",
    "\n",
    "# Save vocabulary mappings (needed for tokenization in Task 2)\n",
    "with open('model/vocab.pkl', 'wb') as f:\n",
    "    pickle.dump({\n",
    "        'word2id': word2id,\n",
    "        'id2word': id2word,\n",
    "        'vocab_size': vocab_size,\n",
    "    }, f)\n",
    "\n",
    "print(\"Model saved to model/bert_pretrained.pth\")\n",
    "print(\"Vocabulary saved to model/vocab.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c3b0c45",
   "metadata": {},
   "source": [
    "## Task 2. Sentence Embedding with Sentence BERT\n",
    "**Implement trained BERT from task 1 with siamese network structures to derive semantically meaningful sentence embeddings that can be compared using cosine-similarity. (3 points)**\n",
    "\n",
    "1) Use the SNLI OR MNLI datasets from Hugging Face, or any dataset related to classification tasks.\n",
    "2) Reproduce training the Sentence-BERT as described in the paper.\n",
    "3) Focus on the Classification Objective Function: (SoftmaxLoss)\n",
    "\n",
    "$$o=softmax(W^{T}\\cdot(u,v,|u-v|))$$\n",
    "\n",
    "**HINT:** You can take a look how to implement Softmax loss in the file 04 Huggingface/Appendix - Sentence Embedding/S-BERT.ipynb.\n",
    "\n",
    "![/assets/SBERT.png](assets/SBERT.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50dff705",
   "metadata": {},
   "source": [
    "### Load Pre-trained BERT and Vocabulary\n",
    "\n",
    "I load the pre-trained BERT model from Task 1 along with the vocabulary mappings. If the model/vocab are already in memory from Task 1, this step ensures they can also be loaded independently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5edcf7ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 199405\n",
      "Pre-trained BERT model loaded successfully!\n",
      "Model config: {'n_layers': 6, 'n_heads': 8, 'd_model': 768, 'd_ff': 3072, 'd_k': 64, 'n_segments': 2, 'vocab_size': 199405, 'max_len': 512}\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "# Load vocabulary mappings\n",
    "with open('model/vocab.pkl', 'rb') as f:\n",
    "    vocab_data = pickle.load(f)\n",
    "    word2id = vocab_data['word2id']\n",
    "    id2word = vocab_data['id2word']\n",
    "    vocab_size = vocab_data['vocab_size']\n",
    "\n",
    "print(f\"Vocabulary size: {vocab_size}\")\n",
    "\n",
    "# Load the pre-trained BERT model checkpoint\n",
    "checkpoint = torch.load('model/bert_pretrained.pth', map_location=device)\n",
    "params = checkpoint['model_params']\n",
    "\n",
    "# Reconstruct the BERT model with the same hyperparameters\n",
    "bert_model = BERT(\n",
    "    n_layers=params['n_layers'],\n",
    "    n_heads=params['n_heads'],\n",
    "    d_model=params['d_model'],\n",
    "    d_ff=params['d_ff'],\n",
    "    d_k=params['d_k'],\n",
    "    n_segments=params['n_segments'],\n",
    "    vocab_size=params['vocab_size'],\n",
    "    max_len=params['max_len'],\n",
    "    device=device\n",
    ").to(device)\n",
    "\n",
    "# Load the pre-trained weights\n",
    "bert_model.load_state_dict(checkpoint['model_state_dict'])\n",
    "print(\"Pre-trained BERT model loaded successfully!\")\n",
    "print(f\"Model config: {params}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88f2bc51",
   "metadata": {},
   "source": [
    "### Load NLI Dataset (SNLI)\n",
    "\n",
    "I use the **SNLI (Stanford Natural Language Inference)** dataset for training Sentence-BERT. SNLI is one of the most widely used benchmarks for natural language inference, containing approximately 570K human-annotated sentence pairs. Each pair consists of a premise and a hypothesis, labeled as entailment, neutral, or contradiction.\n",
    "\n",
    "|Dataset Split|\tNumber of Instances in Split|\n",
    "| :--:| :--: |\n",
    "|Train|\t550,152|\n",
    "|Validation|\t10,000|\n",
    "|Test|\t10,000|\n",
    "\n",
    "Labels: `0 = entailment`, `1 = neutral`, `2 = contradiction`\n",
    "\n",
    "I filter out samples with label `-1` (where annotators could not agree on a label).\n",
    "\n",
    "**Dataset source:** https://huggingface.co/datasets/stanfordnlp/snli\n",
    "\n",
    "```bibtex\n",
    "@inproceedings{bowman-etal-2015-large,\n",
    "    title = \"A large annotated corpus for learning natural language inference\",\n",
    "    author = \"Bowman, Samuel R.  and\n",
    "      Angeli, Gabor  and\n",
    "      Potts, Christopher  and\n",
    "      Manning, Christopher D.\",\n",
    "    editor = \"M{\\`a}rquez, Llu{\\'\\i}s  and\n",
    "      Callison-Burch, Chris  and\n",
    "      Su, Jian\",\n",
    "    booktitle = \"Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing\",\n",
    "    month = sep,\n",
    "    year = \"2015\",\n",
    "    address = \"Lisbon, Portugal\",\n",
    "    publisher = \"Association for Computational Linguistics\",\n",
    "    url = \"https://aclanthology.org/D15-1075\",\n",
    "    doi = \"10.18653/v1/D15-1075\",\n",
    "    pages = \"632--642\",\n",
    "}\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5097a146",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SNLI splits: ['test', 'validation', 'train']\n",
      "SNLI features: {'premise': Value('string'), 'hypothesis': Value('string'), 'label': ClassLabel(names=['entailment', 'neutral', 'contradiction'])}\n",
      "SNLI train size: 550,152\n",
      "SNLI test size: 10,000\n",
      "SNLI validation size: 10,000\n"
     ]
    }
   ],
   "source": [
    "# Load SNLI dataset from Hugging Face\n",
    "snli = datasets.load_dataset('stanfordnlp/snli')\n",
    "\n",
    "print(f\"SNLI splits: {list(snli.keys())}\")\n",
    "print(f\"SNLI features: {snli['train'].features}\")\n",
    "print(f\"SNLI train size: {len(snli['train']):,}\")\n",
    "print(f\"SNLI test size: {len(snli['test']):,}\")\n",
    "print(f\"SNLI validation size: {len(snli['validation']):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1628baed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SNLI train labels: [0 1 2]\n",
      "SNLI test labels:  [0 1 2]\n",
      "SNLI val labels:   [0 1 2]\n",
      "\n",
      "Filtered sizes:\n",
      "  Train:      549,367\n",
      "  Test:       9,824\n",
      "  Validation: 9,842\n"
     ]
    }
   ],
   "source": [
    "# Filter out samples with label = -1 in SNLI (where no agreement was reached)\n",
    "snli = snli.filter(lambda x: x['label'] != -1)\n",
    "\n",
    "# Verify labels are clean\n",
    "print(f\"SNLI train labels: {np.unique(snli['train']['label'])}\")\n",
    "print(f\"SNLI test labels:  {np.unique(snli['test']['label'])}\")\n",
    "print(f\"SNLI val labels:   {np.unique(snli['validation']['label'])}\")\n",
    "print(f\"\\nFiltered sizes:\")\n",
    "print(f\"  Train:      {len(snli['train']):,}\")\n",
    "print(f\"  Test:       {len(snli['test']):,}\")\n",
    "print(f\"  Validation: {len(snli['validation']):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2e333556",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NLI Dataset splits:\n",
      "  Train:      50,000 samples\n",
      "  Test:       9,824 samples\n",
      "  Validation: 9,842 samples\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['premise', 'hypothesis', 'label'],\n",
       "        num_rows: 50000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['premise', 'hypothesis', 'label'],\n",
       "        num_rows: 9824\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['premise', 'hypothesis', 'label'],\n",
       "        num_rows: 9842\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create NLI dataset from SNLI with subsets for manageable training time\n",
    "# Use min() to handle splits smaller than the desired subset size\n",
    "nli_dataset = DatasetDict({\n",
    "    'train': snli['train'].shuffle(seed=SEED).select(range(min(50000, len(snli['train'])))),\n",
    "    'test': snli['test'].shuffle(seed=SEED).select(range(min(10000, len(snli['test'])))),\n",
    "    'validation': snli['validation'].shuffle(seed=SEED).select(range(min(10000, len(snli['validation']))))\n",
    "})\n",
    "# NOTE: Remove .select(...) to use the full SNLI dataset for better performance\n",
    "\n",
    "print(f\"NLI Dataset splits:\")\n",
    "print(f\"  Train:      {len(nli_dataset['train']):,} samples\")\n",
    "print(f\"  Test:       {len(nli_dataset['test']):,} samples\")\n",
    "print(f\"  Validation: {len(nli_dataset['validation']):,} samples\")\n",
    "nli_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01090a6b",
   "metadata": {},
   "source": [
    "### Tokenization for Sentence-BERT\n",
    "\n",
    "Unlike the original BERT which takes a sentence pair as a single input, Sentence-BERT uses a **Siamese network structure** where each sentence is processed independently through the same BERT encoder. Therefore, I tokenize the premise and hypothesis separately.\n",
    "\n",
    "Each sentence is:\n",
    "1. Lowercased and cleaned (matching the vocabulary from Task 1)\n",
    "2. Converted to token IDs using the custom vocabulary\n",
    "3. Wrapped with `[CLS]` and `[SEP]` tokens\n",
    "4. Padded to the same maximum length\n",
    "5. Accompanied by segment IDs (all zeros since each is a single sentence) and attention masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1a208caa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input:          'A man is playing a guitar on stage.'\n",
      "Token IDs:      [1, 17004, 58622, 44820, 2978, 17004, 97792, 154449, 172925, 2, 0, 0, 0, 0, 0]...\n",
      "Attention Mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]...\n",
      "Segment IDs:    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]...\n"
     ]
    }
   ],
   "source": [
    "def tokenize_sentence(sentence, word2id, max_seq_length=128):\n",
    "    \"\"\"\n",
    "    Tokenize a single sentence using the custom vocabulary from Task 1.\n",
    "    \n",
    "    Steps:\n",
    "    1. Lowercase and clean the text (remove punctuation)\n",
    "    2. Split into words and convert to token IDs\n",
    "    3. Add [CLS] and [SEP] special tokens\n",
    "    4. Truncate to max_seq_length\n",
    "    5. Create attention mask (1 for real tokens, 0 for padding)\n",
    "    6. Pad to max_seq_length\n",
    "    \n",
    "    Args:\n",
    "        sentence: Raw text string\n",
    "        word2id: Vocabulary mapping (word -> id)\n",
    "        max_seq_length: Maximum sequence length after adding special tokens\n",
    "        \n",
    "    Returns:\n",
    "        input_ids: List of token IDs\n",
    "        attention_mask: List of 1s and 0s\n",
    "        segment_ids: List of 0s (single sentence)\n",
    "    \"\"\"\n",
    "    # Clean and lowercase (same preprocessing as Task 1)\n",
    "    cleaned = re.sub(\"[.,!?\\\\-]\", '', sentence.lower())\n",
    "    words = cleaned.split()\n",
    "    \n",
    "    # Convert words to token IDs, using [MASK] token for unknown words\n",
    "    token_ids = [word2id.get(w, word2id['[MASK]']) for w in words]\n",
    "    \n",
    "    # Add [CLS] at the start and [SEP] at the end\n",
    "    input_ids = [word2id['[CLS]']] + token_ids + [word2id['[SEP]']]\n",
    "    \n",
    "    # Truncate if necessary (keep [CLS] at start and [SEP] at end)\n",
    "    if len(input_ids) > max_seq_length:\n",
    "        input_ids = input_ids[:max_seq_length - 1] + [word2id['[SEP]']]\n",
    "    \n",
    "    # Create attention mask before padding (1 for real tokens)\n",
    "    attention_mask = [1] * len(input_ids)\n",
    "    \n",
    "    # Segment IDs are all 0 (single sentence input)\n",
    "    segment_ids = [0] * len(input_ids)\n",
    "    \n",
    "    # Pad to max_seq_length\n",
    "    padding_length = max_seq_length - len(input_ids)\n",
    "    input_ids += [word2id['[PAD]']] * padding_length\n",
    "    attention_mask += [0] * padding_length\n",
    "    segment_ids += [0] * padding_length\n",
    "    \n",
    "    return input_ids, attention_mask, segment_ids\n",
    "\n",
    "\n",
    "def preprocess_nli(examples, word2id, max_seq_length=128):\n",
    "    \"\"\"\n",
    "    Preprocess NLI dataset examples for Sentence-BERT.\n",
    "    \n",
    "    Tokenizes premise and hypothesis separately (Siamese network approach)\n",
    "    and returns all necessary tensors for training.\n",
    "    \n",
    "    Args:\n",
    "        examples: Batch of examples from the NLI dataset\n",
    "        word2id: Vocabulary mapping\n",
    "        max_seq_length: Maximum sequence length\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary with tokenized premise and hypothesis, plus labels\n",
    "    \"\"\"\n",
    "    premise_input_ids, premise_attention_masks, premise_segment_ids = [], [], []\n",
    "    hypo_input_ids, hypo_attention_masks, hypo_segment_ids = [], [], []\n",
    "    \n",
    "    for premise, hypothesis in zip(examples['premise'], examples['hypothesis']):\n",
    "        # Tokenize premise\n",
    "        p_ids, p_mask, p_seg = tokenize_sentence(premise, word2id, max_seq_length)\n",
    "        premise_input_ids.append(p_ids)\n",
    "        premise_attention_masks.append(p_mask)\n",
    "        premise_segment_ids.append(p_seg)\n",
    "        \n",
    "        # Tokenize hypothesis  \n",
    "        h_ids, h_mask, h_seg = tokenize_sentence(hypothesis, word2id, max_seq_length)\n",
    "        hypo_input_ids.append(h_ids)\n",
    "        hypo_attention_masks.append(h_mask)\n",
    "        hypo_segment_ids.append(h_seg)\n",
    "    \n",
    "    return {\n",
    "        \"premise_input_ids\": premise_input_ids,\n",
    "        \"premise_attention_mask\": premise_attention_masks,\n",
    "        \"premise_segment_ids\": premise_segment_ids,\n",
    "        \"hypothesis_input_ids\": hypo_input_ids,\n",
    "        \"hypothesis_attention_mask\": hypo_attention_masks,\n",
    "        \"hypothesis_segment_ids\": hypo_segment_ids,\n",
    "        \"labels\": examples[\"label\"]\n",
    "    }\n",
    "\n",
    "# Test tokenization on a sample\n",
    "sample_sentence = \"A man is playing a guitar on stage.\"\n",
    "ids, mask, seg = tokenize_sentence(sample_sentence, word2id)\n",
    "print(f\"Input:          '{sample_sentence}'\")\n",
    "print(f\"Token IDs:      {ids[:15]}...\")\n",
    "print(f\"Attention Mask: {mask[:15]}...\")\n",
    "print(f\"Segment IDs:    {seg[:15]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "64814cd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenizing NLI dataset: 100%|██████████| 50000/50000 [00:03<00:00, 15359.91 examples/s]\n",
      "Tokenizing NLI dataset: 100%|██████████| 9824/9824 [00:00<00:00, 12420.97 examples/s]\n",
      "Tokenizing NLI dataset: 100%|██████████| 9842/9842 [00:00<00:00, 17579.48 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenized dataset columns: ['premise_input_ids', 'premise_attention_mask', 'premise_segment_ids', 'hypothesis_input_ids', 'hypothesis_attention_mask', 'hypothesis_segment_ids', 'labels']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['premise_input_ids', 'premise_attention_mask', 'premise_segment_ids', 'hypothesis_input_ids', 'hypothesis_attention_mask', 'hypothesis_segment_ids', 'labels'],\n",
       "        num_rows: 50000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['premise_input_ids', 'premise_attention_mask', 'premise_segment_ids', 'hypothesis_input_ids', 'hypothesis_attention_mask', 'hypothesis_segment_ids', 'labels'],\n",
       "        num_rows: 9824\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['premise_input_ids', 'premise_attention_mask', 'premise_segment_ids', 'hypothesis_input_ids', 'hypothesis_attention_mask', 'hypothesis_segment_ids', 'labels'],\n",
       "        num_rows: 9842\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply preprocessing to the entire NLI dataset\n",
    "sbert_max_seq_length = 128\n",
    "\n",
    "tokenized_nli = nli_dataset.map(\n",
    "    lambda examples: preprocess_nli(examples, word2id, sbert_max_seq_length),\n",
    "    batched=True,\n",
    "    desc=\"Tokenizing NLI dataset\"\n",
    ")\n",
    "\n",
    "# Remove original text columns and keep only tokenized versions\n",
    "tokenized_nli = tokenized_nli.remove_columns(['premise', 'hypothesis', 'label'])\n",
    "\n",
    "# Set format to PyTorch tensors for use with DataLoader\n",
    "tokenized_nli.set_format(\"torch\")\n",
    "\n",
    "print(f\"Tokenized dataset columns: {tokenized_nli['train'].column_names}\")\n",
    "tokenized_nli"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f0e1acf",
   "metadata": {},
   "source": [
    "### DataLoaders for Sentence-BERT Training\n",
    "\n",
    "I create PyTorch DataLoaders for the train, validation, and test splits. The training data is shuffled to ensure the model sees diverse examples each epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "56f48b99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Premise input_ids:      torch.Size([32, 128])\n",
      "Premise attention_mask: torch.Size([32, 128])\n",
      "Premise segment_ids:    torch.Size([32, 128])\n",
      "Hypothesis input_ids:   torch.Size([32, 128])\n",
      "Labels:                 torch.Size([32])\n"
     ]
    }
   ],
   "source": [
    "# Batch size for S-BERT training\n",
    "sbert_batch_size = 32\n",
    "\n",
    "# Create DataLoaders for each split\n",
    "train_dataloader = DataLoader(\n",
    "    tokenized_nli['train'],\n",
    "    batch_size=sbert_batch_size,\n",
    "    shuffle=True\n",
    ")\n",
    "eval_dataloader = DataLoader(\n",
    "    tokenized_nli['validation'],\n",
    "    batch_size=sbert_batch_size\n",
    ")\n",
    "test_dataloader = DataLoader(\n",
    "    tokenized_nli['test'],\n",
    "    batch_size=sbert_batch_size\n",
    ")\n",
    "\n",
    "# Verify batch shapes\n",
    "for batch in train_dataloader:\n",
    "    print(f\"Premise input_ids:      {batch['premise_input_ids'].shape}\")\n",
    "    print(f\"Premise attention_mask: {batch['premise_attention_mask'].shape}\")\n",
    "    print(f\"Premise segment_ids:    {batch['premise_segment_ids'].shape}\")\n",
    "    print(f\"Hypothesis input_ids:   {batch['hypothesis_input_ids'].shape}\")\n",
    "    print(f\"Labels:                 {batch['labels'].shape}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81701aad",
   "metadata": {},
   "source": [
    "### Mean Pooling and Classification Head\n",
    "\n",
    "Following the Sentence-BERT paper, I add a **mean pooling** layer on top of BERT's token-level outputs to produce fixed-size sentence embeddings. Mean pooling computes the average of all token embeddings, weighted by the attention mask (so padding tokens are excluded).\n",
    "\n",
    "For the **Classification Objective Function**, I concatenate the two sentence embeddings $u$ and $v$ with their element-wise absolute difference $|u - v|$, then pass through a softmax classifier:\n",
    "\n",
    "$$o = \\text{softmax}\\left(W^T \\cdot (u, v, |u - v|)\\right)$$\n",
    "\n",
    "Where $W \\in \\mathbb{R}^{3n \\times k}$ with $n$ = embedding dimension (768) and $k$ = number of classes (3).\n",
    "\n",
    "This captures not just the individual sentence representations, but also the relationship between them through the difference vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2eff7a72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier head: Linear(2304, 3)\n",
      "Learning rate: 2e-5\n"
     ]
    }
   ],
   "source": [
    "def mean_pool(token_embeds, attention_mask):\n",
    "    \"\"\"\n",
    "    Perform mean pooling on BERT token embeddings, excluding padding tokens.\n",
    "    \n",
    "    For each sentence in the batch, I compute the mean of token embeddings\n",
    "    where the attention mask is 1 (i.e., real tokens, not padding).\n",
    "    \n",
    "    Args:\n",
    "        token_embeds: BERT output embeddings (batch_size, seq_len, hidden_dim)\n",
    "        attention_mask: Binary mask (batch_size, seq_len) where 1 = real token, 0 = padding\n",
    "        \n",
    "    Returns:\n",
    "        Pooled sentence embeddings (batch_size, hidden_dim)\n",
    "    \"\"\"\n",
    "    # Expand attention mask to match embedding dimensions: (batch_size, seq_len) -> (batch_size, seq_len, hidden_dim)\n",
    "    in_mask = attention_mask.unsqueeze(-1).expand(token_embeds.size()).float()\n",
    "    # Sum embeddings for non-padding tokens and divide by the count of non-padding tokens\n",
    "    pool = torch.sum(token_embeds * in_mask, 1) / torch.clamp(in_mask.sum(1), min=1e-9)\n",
    "    return pool\n",
    "\n",
    "\n",
    "# Initialize the classification head: maps concatenated [u; v; |u-v|] to 3 NLI classes\n",
    "# Input dimension = 3 * d_model (u, v, and |u-v| each have d_model dimensions)\n",
    "d_model_sbert = params['d_model']\n",
    "classifier_head = nn.Linear(d_model_sbert * 3, 3).to(device)\n",
    "\n",
    "# Set up optimizers for both the BERT backbone and the classifier head\n",
    "optimizer_bert = optim.Adam(bert_model.parameters(), lr=2e-5)\n",
    "optimizer_classifier = optim.Adam(classifier_head.parameters(), lr=2e-5)\n",
    "\n",
    "# Cross-entropy loss for 3-class classification\n",
    "criterion_sbert = nn.CrossEntropyLoss()\n",
    "\n",
    "print(f\"Classifier head: Linear({d_model_sbert * 3}, 3)\")\n",
    "print(f\"Learning rate: 2e-5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afadd2ae",
   "metadata": {},
   "source": [
    "### Sentence-BERT Model Summary\n",
    "\n",
    "The Sentence-BERT architecture extends the pre-trained BERT from Task 1 with a Siamese network structure and a classification head. Below is a summary of the complete S-BERT pipeline.\n",
    "\n",
    "| Component | Detail |\n",
    "|---|---|\n",
    "| **BERT Backbone** | Same as Task 1 (6 layers, 8 heads, d_model=768) |\n",
    "| **Pooling Strategy** | Mean pooling over token embeddings (excluding padding) |\n",
    "| **Classifier Input** | Concatenation of $[u; v; \\|u-v\\|]$ → dimension = 3 × 768 = 2,304 |\n",
    "| **Classifier Output** | 3 classes (entailment, neutral, contradiction) |\n",
    "| **NLI Dataset** | SNLI (50K train / 9,824 test / 9,842 validation) |\n",
    "| **Optimizer** | Adam (lr = 2e-5) for both BERT backbone and classifier |\n",
    "| **Scheduler** | Linear warmup (10%) + linear decay |\n",
    "| **Epochs** | 5 |\n",
    "| **Batch Size** | 32 |\n",
    "| **Loss Function** | CrossEntropyLoss (Softmax Loss) |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8418cb39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training steps: 7815\n",
      "Warmup steps: 781\n",
      "Number of epochs: 5\n"
     ]
    }
   ],
   "source": [
    "# Calculate total training steps and warmup steps\n",
    "sbert_num_epochs = 5\n",
    "total_steps = len(train_dataloader) * sbert_num_epochs\n",
    "warmup_steps = int(0.1 * total_steps)  # 10% warmup\n",
    "\n",
    "# Learning rate schedulers with linear warmup then linear decay\n",
    "scheduler_bert = get_linear_schedule_with_warmup(\n",
    "    optimizer_bert,\n",
    "    num_warmup_steps=warmup_steps,\n",
    "    num_training_steps=total_steps\n",
    ")\n",
    "scheduler_classifier = get_linear_schedule_with_warmup(\n",
    "    optimizer_classifier,\n",
    "    num_warmup_steps=warmup_steps,\n",
    "    num_training_steps=total_steps\n",
    ")\n",
    "\n",
    "print(f\"Total training steps: {total_steps}\")\n",
    "print(f\"Warmup steps: {warmup_steps}\")\n",
    "print(f\"Number of epochs: {sbert_num_epochs}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "913ebc61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "Sentence-BERT Architecture\n",
      "======================================================================\n",
      "\n",
      "[BERT Backbone]  (fine-tuned from Task 1)\n",
      "  Parameters:      192,717,807\n",
      "  Trainable:       192,717,807\n",
      "\n",
      "[Classifier Head]  Linear(2304 → 3)\n",
      "  Parameters:            6,915\n",
      "  Trainable:             6,915\n",
      "Linear(in_features=2304, out_features=3, bias=True)\n",
      "\n",
      "[Total S-BERT System]\n",
      "  Parameters:      192,724,722\n",
      "  Trainable:       192,724,722\n",
      "\n",
      "======================================================================\n",
      "S-BERT Training Hyperparameters\n",
      "======================================================================\n",
      "  BERT backbone            : 6L / 8H / d_model=768\n",
      "  Pooling                  : Mean pooling (excl. padding)\n",
      "  Classifier input dim     : 3 × 768 = 2304\n",
      "  Classifier output        : 3 (entailment / neutral / contradiction)\n",
      "  Optimizer                : Adam (lr=2e-5)\n",
      "  Scheduler                : Linear warmup (10%) + decay\n",
      "  Epochs                   : 5\n",
      "  Batch size               : 32\n",
      "  Loss                     : CrossEntropyLoss (Softmax)\n",
      "  Dataset                  : SNLI (Stanford NLI)\n"
     ]
    }
   ],
   "source": [
    "# ==================== Sentence-BERT Model Structure & Parameters ====================\n",
    "print(\"=\" * 70)\n",
    "print(\"Sentence-BERT Architecture\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# BERT backbone summary\n",
    "bert_total = sum(p.numel() for p in bert_model.parameters())\n",
    "bert_trainable = sum(p.numel() for p in bert_model.parameters() if p.requires_grad)\n",
    "\n",
    "# Classifier head summary\n",
    "cls_total = sum(p.numel() for p in classifier_head.parameters())\n",
    "cls_trainable = sum(p.numel() for p in classifier_head.parameters() if p.requires_grad)\n",
    "\n",
    "print(f\"\\n[BERT Backbone]  (fine-tuned from Task 1)\")\n",
    "print(f\"  Parameters:     {bert_total:>12,}\")\n",
    "print(f\"  Trainable:      {bert_trainable:>12,}\")\n",
    "\n",
    "print(f\"\\n[Classifier Head]  Linear({d_model_sbert * 3} → 3)\")\n",
    "print(f\"  Parameters:     {cls_total:>12,}\")\n",
    "print(f\"  Trainable:      {cls_trainable:>12,}\")\n",
    "print(classifier_head)\n",
    "\n",
    "print(f\"\\n[Total S-BERT System]\")\n",
    "print(f\"  Parameters:     {bert_total + cls_total:>12,}\")\n",
    "print(f\"  Trainable:      {bert_trainable + cls_trainable:>12,}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"S-BERT Training Hyperparameters\")\n",
    "print(\"=\" * 70)\n",
    "sbert_hyperparams = {\n",
    "    \"BERT backbone\": f\"{params['n_layers']}L / {params['n_heads']}H / d_model={params['d_model']}\",\n",
    "    \"Pooling\": \"Mean pooling (excl. padding)\",\n",
    "    \"Classifier input dim\": f\"3 × {params['d_model']} = {3 * params['d_model']}\",\n",
    "    \"Classifier output\": \"3 (entailment / neutral / contradiction)\",\n",
    "    \"Optimizer\": \"Adam (lr=2e-5)\",\n",
    "    \"Scheduler\": \"Linear warmup (10%) + decay\",\n",
    "    \"Epochs\": sbert_num_epochs,\n",
    "    \"Batch size\": sbert_batch_size,\n",
    "    \"Loss\": \"CrossEntropyLoss (Softmax)\",\n",
    "    \"Dataset\": \"SNLI (Stanford NLI)\",\n",
    "}\n",
    "for k, v in sbert_hyperparams.items():\n",
    "    print(f\"  {k:25s}: {v}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07369c71",
   "metadata": {},
   "source": [
    "### Sentence-BERT Training Loop\n",
    "\n",
    "I train the Sentence-BERT model using the Classification Objective Function. For each batch:\n",
    "\n",
    "1. **Encode** both premise and hypothesis through the shared BERT encoder\n",
    "2. **Pool** token-level outputs into sentence embeddings using mean pooling\n",
    "3. **Concatenate** $u$, $v$, and $|u - v|$ to form the classifier input\n",
    "4. **Classify** into 3 NLI classes (entailment, neutral, contradiction)\n",
    "5. **Backpropagate** the cross-entropy loss through both the classifier and BERT backbone\n",
    "\n",
    "This fine-tunes the BERT encoder to produce sentence embeddings that are semantically meaningful for the NLI classification task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d2819dab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5: 100%|██████████| 1563/1563 [05:31<00:00,  4.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5 | Avg Loss: 1.0245 | Train Accuracy: 45.83%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/5: 100%|██████████| 1563/1563 [05:32<00:00,  4.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/5 | Avg Loss: 0.8890 | Train Accuracy: 58.38%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/5: 100%|██████████| 1563/1563 [05:31<00:00,  4.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/5 | Avg Loss: 0.8265 | Train Accuracy: 62.61%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/5: 100%|██████████| 1563/1563 [05:31<00:00,  4.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/5 | Avg Loss: 0.7795 | Train Accuracy: 65.59%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/5: 100%|██████████| 1563/1563 [05:31<00:00,  4.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/5 | Avg Loss: 0.7336 | Train Accuracy: 68.20%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# ==================== Sentence-BERT Training Loop ====================\n",
    "for epoch in range(sbert_num_epochs):\n",
    "    bert_model.train()\n",
    "    classifier_head.train()\n",
    "    epoch_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    # Training loop with progress bar\n",
    "    for step, batch in enumerate(tqdm(train_dataloader, desc=f\"Epoch {epoch + 1}/{sbert_num_epochs}\", leave=True)):\n",
    "        # Zero all gradients\n",
    "        optimizer_bert.zero_grad()\n",
    "        optimizer_classifier.zero_grad()\n",
    "        \n",
    "        # Move batch tensors to device\n",
    "        premise_ids = batch['premise_input_ids'].to(device)\n",
    "        premise_mask = batch['premise_attention_mask'].to(device)\n",
    "        premise_seg = batch['premise_segment_ids'].to(device)\n",
    "        hypo_ids = batch['hypothesis_input_ids'].to(device)\n",
    "        hypo_mask = batch['hypothesis_attention_mask'].to(device)\n",
    "        hypo_seg = batch['hypothesis_segment_ids'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "        \n",
    "        # Encode premise through BERT (get last hidden state for all tokens)\n",
    "        u_hidden = bert_model.get_last_hidden_state(premise_ids, premise_seg)\n",
    "        # Encode hypothesis through the same BERT (Siamese structure)\n",
    "        v_hidden = bert_model.get_last_hidden_state(hypo_ids, hypo_seg)\n",
    "        \n",
    "        # Apply mean pooling to get fixed-size sentence embeddings\n",
    "        u = mean_pool(u_hidden, premise_mask)   # (batch_size, d_model)\n",
    "        v = mean_pool(v_hidden, hypo_mask)       # (batch_size, d_model)\n",
    "        \n",
    "        # Compute |u - v| (element-wise absolute difference)\n",
    "        uv_abs = torch.abs(u - v)                # (batch_size, d_model)\n",
    "        \n",
    "        # Concatenate [u; v; |u-v|] as input to the classifier\n",
    "        x = torch.cat([u, v, uv_abs], dim=-1)    # (batch_size, 3 * d_model)\n",
    "        \n",
    "        # Pass through classifier head to get logits for 3 NLI classes\n",
    "        logits = classifier_head(x)               # (batch_size, 3)\n",
    "        \n",
    "        # Compute cross-entropy loss (softmax loss)\n",
    "        loss = criterion_sbert(logits, labels)\n",
    "        \n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        \n",
    "        # Update parameters\n",
    "        optimizer_bert.step()\n",
    "        optimizer_classifier.step()\n",
    "        \n",
    "        # Update learning rate schedulers\n",
    "        scheduler_bert.step()\n",
    "        scheduler_classifier.step()\n",
    "        \n",
    "        # Track metrics\n",
    "        epoch_loss += loss.item()\n",
    "        predictions = torch.argmax(logits, dim=-1)\n",
    "        correct += (predictions == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "    \n",
    "    # Print epoch summary\n",
    "    avg_loss = epoch_loss / len(train_dataloader)\n",
    "    accuracy = correct / total * 100\n",
    "    print(f\"Epoch {epoch + 1}/{sbert_num_epochs} | Avg Loss: {avg_loss:.4f} | Train Accuracy: {accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1365ea0b",
   "metadata": {},
   "source": [
    "### Save Sentence-BERT Model\n",
    "\n",
    "Save the fine-tuned Sentence-BERT model (BERT backbone + classifier head) for use in evaluation (Task 3) and the web application (Task 4)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f36787c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence-BERT model saved to model/sbert_nli.pth\n"
     ]
    }
   ],
   "source": [
    "# Save the fine-tuned S-BERT model\n",
    "torch.save({\n",
    "    'bert_state_dict': bert_model.state_dict(),\n",
    "    'classifier_state_dict': classifier_head.state_dict(),\n",
    "    'model_params': bert_model.params,\n",
    "}, 'model/sbert_nli.pth')\n",
    "\n",
    "print(\"Sentence-BERT model saved to model/sbert_nli.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fae45dc",
   "metadata": {},
   "source": [
    "### Sentence-BERT Inference: Text Similarity and NLI Prediction\n",
    "\n",
    "I define inference functions to:\n",
    "1. **Generate sentence embeddings** from raw text using the fine-tuned S-BERT\n",
    "2. **Compute cosine similarity** between two sentences\n",
    "3. **Predict NLI labels** (entailment, neutral, contradiction) for sentence pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c26949d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Sentence-BERT Inference Examples\n",
      "================================================================================\n",
      "\n",
      "Premise:    A man is playing a guitar on stage.\n",
      "Hypothesis: The man is performing music.\n",
      "Prediction: entailment (confidence: 0.7269)\n",
      "Cosine Similarity: 0.7582\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Premise:    A woman is reading a book in the park.\n",
      "Hypothesis: The woman is sleeping at home.\n",
      "Prediction: contradiction (confidence: 0.8922)\n",
      "Cosine Similarity: 0.9885\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Premise:    The children are playing soccer.\n",
      "Hypothesis: Nobody is playing any sport.\n",
      "Prediction: contradiction (confidence: 0.9989)\n",
      "Cosine Similarity: -0.7283\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity as sklearn_cosine_similarity\n",
    "\n",
    "# NLI label mapping\n",
    "LABEL_MAP = {0: 'entailment', 1: 'neutral', 2: 'contradiction'}\n",
    "\n",
    "def get_sentence_embedding(model, sentence, word2id, device, max_seq_length=128):\n",
    "    \"\"\"\n",
    "    Generate a fixed-size sentence embedding from raw text using the fine-tuned BERT.\n",
    "    \n",
    "    Args:\n",
    "        model: Fine-tuned BERT model  \n",
    "        sentence: Raw text string\n",
    "        word2id: Vocabulary mapping\n",
    "        device: Computation device (CPU/GPU)\n",
    "        max_seq_length: Maximum sequence length\n",
    "        \n",
    "    Returns:\n",
    "        Sentence embedding as numpy array (hidden_dim,)\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        # Tokenize the sentence\n",
    "        input_ids, attention_mask, segment_ids = tokenize_sentence(sentence, word2id, max_seq_length)\n",
    "        \n",
    "        # Convert to tensors and add batch dimension\n",
    "        input_ids = torch.LongTensor([input_ids]).to(device)\n",
    "        attention_mask = torch.LongTensor([attention_mask]).to(device)\n",
    "        segment_ids = torch.LongTensor([segment_ids]).to(device)\n",
    "        \n",
    "        # Get last hidden state from BERT\n",
    "        hidden_state = model.get_last_hidden_state(input_ids, segment_ids)\n",
    "        \n",
    "        # Apply mean pooling to get sentence embedding\n",
    "        embedding = mean_pool(hidden_state, attention_mask)\n",
    "        \n",
    "    return embedding.cpu().numpy().reshape(-1)\n",
    "\n",
    "\n",
    "def predict_nli(model, classifier, sentence_a, sentence_b, word2id, device, max_seq_length=128):\n",
    "    \"\"\"\n",
    "    Predict the NLI relationship between two sentences.\n",
    "    \n",
    "    Args:\n",
    "        model: Fine-tuned BERT model\n",
    "        classifier: Classification head\n",
    "        sentence_a: Premise text\n",
    "        sentence_b: Hypothesis text\n",
    "        word2id: Vocabulary mapping\n",
    "        device: Computation device\n",
    "        max_seq_length: Maximum sequence length\n",
    "        \n",
    "    Returns:\n",
    "        Tuple of (predicted_label, confidence, similarity_score)\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    classifier.eval()\n",
    "    with torch.no_grad():\n",
    "        # Get sentence embeddings\n",
    "        u = get_sentence_embedding(model, sentence_a, word2id, device, max_seq_length)\n",
    "        v = get_sentence_embedding(model, sentence_b, word2id, device, max_seq_length)\n",
    "        \n",
    "        # Compute cosine similarity\n",
    "        similarity = sklearn_cosine_similarity(u.reshape(1, -1), v.reshape(1, -1))[0, 0]\n",
    "        \n",
    "        # Convert back to tensors for classification\n",
    "        u_tensor = torch.FloatTensor(u).unsqueeze(0).to(device)\n",
    "        v_tensor = torch.FloatTensor(v).unsqueeze(0).to(device)\n",
    "        \n",
    "        # Compute |u - v|\n",
    "        uv_abs = torch.abs(u_tensor - v_tensor)\n",
    "        \n",
    "        # Concatenate and classify\n",
    "        x = torch.cat([u_tensor, v_tensor, uv_abs], dim=-1)\n",
    "        logits = classifier(x)\n",
    "        probs = F.softmax(logits, dim=-1)\n",
    "        predicted_class = torch.argmax(probs, dim=-1).item()\n",
    "        confidence = probs[0, predicted_class].item()\n",
    "        \n",
    "    return LABEL_MAP[predicted_class], confidence, similarity\n",
    "\n",
    "\n",
    "# Test with example sentence pairs\n",
    "test_pairs = [\n",
    "    (\"A man is playing a guitar on stage.\", \"The man is performing music.\"),\n",
    "    (\"A woman is reading a book in the park.\", \"The woman is sleeping at home.\"),\n",
    "    (\"The children are playing soccer.\", \"Nobody is playing any sport.\"),\n",
    "]\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"Sentence-BERT Inference Examples\")\n",
    "print(\"=\" * 80)\n",
    "for premise, hypothesis in test_pairs:\n",
    "    label, conf, sim = predict_nli(bert_model, classifier_head, premise, hypothesis, word2id, device)\n",
    "    print(f\"\\nPremise:    {premise}\")\n",
    "    print(f\"Hypothesis: {hypothesis}\")\n",
    "    print(f\"Prediction: {label} (confidence: {conf:.4f})\")\n",
    "    print(f\"Cosine Similarity: {sim:.4f}\")\n",
    "    print(\"-\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcdf8286",
   "metadata": {},
   "source": [
    "## Task 3. Evaluation and Analysis (1 points)\n",
    "\n",
    "1) Provide the performance metrics (classification Report) based on the SNLI or MNLI datasets for the Natural Language Inference (NLI) task.\n",
    "\n",
    "**TABLE 1. Classification Report**\n",
    "\n",
    "| | precision | recall | f1-score | support |\n",
    "|---|---|---|---|---|\n",
    "| **entailment** | 0.63 | 0.70 | 0.66 | 3368 |\n",
    "| **neutral** | 0.62 | 0.59 | 0.61 | 3219 |\n",
    "| **contradiction** | 0.63 | 0.59 | 0.61 | 3237 |\n",
    "| **accuracy** | | | 0.63 | 9824 |\n",
    "| **macro avg** | 0.63 | 0.63 | 0.63 | 9824 |\n",
    "| **weighted avg** | 0.63 | 0.63 | 0.63 | 9824 |\n",
    "\n",
    "2) Discuss any limitations or challenges encountered during the implementation and propose potential improvements or modifications.\n",
    "\n",
    "**NOTE:** Make sure to provide proper documentation, including details of the datasets used, hyperparameters, and any modifications made to the original models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28ca4505",
   "metadata": {},
   "source": [
    "### Evaluation on Test Set\n",
    "\n",
    "I evaluate the Sentence-BERT model on the held-out test set by:\n",
    "1. Running inference on all test samples to collect predictions\n",
    "2. Computing a full classification report (precision, recall, F1-score for each class)\n",
    "3. Generating a confusion matrix for visual analysis\n",
    "\n",
    "This evaluation uses the same Classification Objective Function pipeline: BERT encoding → mean pooling → concatenation → classifier head."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9d48aac5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating on test set: 100%|██████████| 307/307 [00:21<00:00, 14.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Classification Report (Test Set)\n",
      "============================================================\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "   entailment       0.63      0.70      0.66      3368\n",
      "      neutral       0.62      0.59      0.61      3219\n",
      "contradiction       0.63      0.59      0.61      3237\n",
      "\n",
      "     accuracy                           0.63      9824\n",
      "    macro avg       0.63      0.63      0.63      9824\n",
      " weighted avg       0.63      0.63      0.63      9824\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ==================== Evaluate on Test Set ====================\n",
    "bert_model.eval()\n",
    "classifier_head.eval()\n",
    "\n",
    "all_predictions = []\n",
    "all_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(test_dataloader, desc=\"Evaluating on test set\"):\n",
    "        # Move batch to device\n",
    "        premise_ids = batch['premise_input_ids'].to(device)\n",
    "        premise_mask = batch['premise_attention_mask'].to(device)\n",
    "        premise_seg = batch['premise_segment_ids'].to(device)\n",
    "        hypo_ids = batch['hypothesis_input_ids'].to(device)\n",
    "        hypo_mask = batch['hypothesis_attention_mask'].to(device)\n",
    "        hypo_seg = batch['hypothesis_segment_ids'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "        \n",
    "        # Encode both sentences through BERT\n",
    "        u_hidden = bert_model.get_last_hidden_state(premise_ids, premise_seg)\n",
    "        v_hidden = bert_model.get_last_hidden_state(hypo_ids, hypo_seg)\n",
    "        \n",
    "        # Mean pooling for sentence embeddings\n",
    "        u = mean_pool(u_hidden, premise_mask)\n",
    "        v = mean_pool(v_hidden, hypo_mask)\n",
    "        \n",
    "        # Compute |u - v| and concatenate\n",
    "        uv_abs = torch.abs(u - v)\n",
    "        x = torch.cat([u, v, uv_abs], dim=-1)\n",
    "        \n",
    "        # Classify\n",
    "        logits = classifier_head(x)\n",
    "        predictions = torch.argmax(logits, dim=-1)\n",
    "        \n",
    "        all_predictions.extend(predictions.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "# Filter out invalid labels (-1 means no annotator agreement)\n",
    "valid_mask = [i for i, l in enumerate(all_labels) if l in [0, 1, 2]]\n",
    "filtered_labels = [all_labels[i] for i in valid_mask]\n",
    "filtered_preds = [all_predictions[i] for i in valid_mask]\n",
    "\n",
    "# Print classification report\n",
    "target_names = ['entailment', 'neutral', 'contradiction']\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"Classification Report (Test Set)\")\n",
    "print(\"=\" * 60)\n",
    "print(classification_report(filtered_labels, filtered_preds, labels=[0, 1, 2], target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "bea94daf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Overall Test Accuracy: 62.87%\n"
     ]
    }
   ],
   "source": [
    "# ==================== Confusion Matrix Visualization ====================\n",
    "# I reuse the filtered labels/predictions (excluding invalid -1 labels) from above\n",
    "cm = confusion_matrix(filtered_labels, filtered_preds, labels=[0, 1, 2])\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "im = ax.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "ax.figure.colorbar(im, ax=ax)\n",
    "\n",
    "# Set labels\n",
    "ax.set(xticks=np.arange(cm.shape[1]),\n",
    "       yticks=np.arange(cm.shape[0]),\n",
    "       xticklabels=target_names,\n",
    "       yticklabels=target_names,\n",
    "       title='Confusion Matrix - NLI Test Set',\n",
    "       ylabel='True Label',\n",
    "       xlabel='Predicted Label')\n",
    "\n",
    "# Rotate tick labels for readability\n",
    "plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\", rotation_mode=\"anchor\")\n",
    "\n",
    "# Annotate cells with counts\n",
    "thresh = cm.max() / 2.\n",
    "for i in range(cm.shape[0]):\n",
    "    for j in range(cm.shape[1]):\n",
    "        ax.text(j, i, format(cm[i, j], 'd'),\n",
    "                ha=\"center\", va=\"center\",\n",
    "                color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print overall accuracy\n",
    "accuracy = np.sum(np.array(filtered_preds) == np.array(filtered_labels)) / len(filtered_labels)\n",
    "print(f\"\\nOverall Test Accuracy: {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25faf00f",
   "metadata": {},
   "source": [
    "### Discussion: Limitations, Challenges, and Potential Improvements\n",
    "\n",
    "#### Limitations and Challenges\n",
    "\n",
    "1. **Custom Vocabulary vs. Subword Tokenization:** I built a word-level vocabulary from the WikiText dataset, which means out-of-vocabulary (OOV) words in the NLI dataset are mapped to the `[MASK]` token. This is a significant limitation compared to BERT's original WordPiece tokenizer, which handles rare words through subword decomposition. Many words in the SNLI premises and hypotheses may not appear in the WikiText vocabulary, leading to information loss.\n",
    "\n",
    "2. **Limited Pre-training Data and Epochs:** Due to computational constraints, I pre-trained BERT on a subset of WikiText-103 (~100K samples) for only 100 epochs with a small batch size of 6. The original BERT was pre-trained on the entire BookCorpus (800M words) and English Wikipedia (2,500M words) for much longer. This limited pre-training means the model has not learned sufficiently rich contextual representations.\n",
    "\n",
    "3. **Simplified Architecture:** While I follow the original BERT architecture, I use 6 layers and 8 heads (similar to BERT-base uses 12 layers and 12 heads). This reduced capacity limits the model's ability to capture complex linguistic patterns.\n",
    "\n",
    "4. **Training Data Subset:** I used only 50K SNLI training samples instead of the full ~550K dataset to keep training time reasonable. More training data would improve generalization.\n",
    "\n",
    "#### Potential Improvements\n",
    "\n",
    "1. **Use a pre-trained tokenizer** (e.g., BertTokenizer from Hugging Face) or train a BPE/WordPiece tokenizer on the dataset to handle OOV words properly.\n",
    "\n",
    "2. **Increase pre-training duration and data:** Train on the full WikiText-103 or BookCorpus dataset for more epochs to learn better language representations before fine-tuning.\n",
    "\n",
    "3. **Use the full SNLI dataset** for S-BERT fine-tuning (all ~550K training samples) to improve downstream performance.\n",
    "\n",
    "4. **Combine SNLI with MNLI** as done in the original S-BERT paper to increase training data diversity across genres.\n",
    "\n",
    "5. **Apply data augmentation** techniques like back-translation or synonym replacement to increase training data diversity.\n",
    "\n",
    "6. **Experiment with different pooling strategies:** The S-BERT paper found that mean pooling works best, but CLS token pooling or max pooling could also be explored.\n",
    "\n",
    "7. **Hyperparameter tuning:** Experiment with different learning rates, batch sizes, and warmup ratios for better convergence."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "761e9a81",
   "metadata": {},
   "source": [
    "## Task 4. Text similarity - Web Application Development\n",
    "**Develop a simple web application that demonstrates the capabilities of your text-embedding model. (1 points)**\n",
    "\n",
    "1) Develop a simple website with two input boxes for search queries.\n",
    "2) Utilize a custom-trained sentence transformer model to predict Natural Language Inference (NLI) Task (entailment, neutral and contradiction).\n",
    "\n",
    "For example:\n",
    "* **Premise:** A man is playing a guitar on stage.\n",
    "* **Hypothesis:** The man is performing music.\n",
    "* **Label:** Entailment\n",
    "\n",
    "Good luck :-)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d24073b4",
   "metadata": {},
   "source": [
    "### Web Application Implementation\n",
    "\n",
    "I developed a Flask web application that demonstrates the NLI capabilities of the trained Sentence-BERT model. The app follows a clean **MVC-style separation** with dedicated files for routing, utilities, templates, and static assets.\n",
    "\n",
    "---\n",
    "\n",
    "#### Project Structure\n",
    "\n",
    "```\n",
    "app/\n",
    "├── app.py                  # Flask application (routes & entry point)\n",
    "├── utils.py                # Model definitions, tokenization, prediction logic\n",
    "├── templates/\n",
    "│   └── index.html          # Jinja2 HTML template\n",
    "└── static/\n",
    "    ├── css/\n",
    "    │   └── style.css       # Stylesheet (loft / minimal aesthetic)\n",
    "    └── js/\n",
    "        └── main.js         # Client-side form handling & result display\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "#### File Descriptions\n",
    "\n",
    "| File | Role | Key Contents |\n",
    "|---|---|---|\n",
    "| `app.py` | **Flask Server** | Initializes Flask app, loads model at startup via `load_model()`, defines two routes: `GET /` (serve page) and `POST /predict` (run inference) |\n",
    "| `utils.py` | **Utilities** | Contains all model class definitions (`Embedding`, `BERT`, etc.), `tokenize_sentence()`, `mean_pool()`, `predict_nli()`, and `load_model()` |\n",
    "| `index.html` | **Template** | Jinja2 template with two `<textarea>` inputs (Premise & Hypothesis), a Predict button, and a result card showing label, confidence, and cosine similarity |\n",
    "| `style.css` | **Styling** | Loft / minimal design: warm beige background (`#f5f0eb`), white card surface, Inter font, subtle shadows, CSS custom properties for theming |\n",
    "| `main.js` | **Client Logic** | Handles form submission via `fetch('/predict')`, manages loading spinner, and dynamically updates the result UI with the JSON response |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2cc77ac",
   "metadata": {},
   "source": [
    "#### How the Web Application Works\n",
    "\n",
    "The application follows a **client-server architecture** where the Flask backend handles model inference and the frontend provides an interactive user interface.\n",
    "\n",
    "---\n",
    "\n",
    "##### 1. Server Startup (`app.py`)\n",
    "\n",
    "When the server starts, it performs a **one-time model loading** step:\n",
    "\n",
    "```python\n",
    "bert_model, classifier_head, word2id, device = load_model(model_dir='../model')\n",
    "```\n",
    "\n",
    "The `load_model()` function in `utils.py`:\n",
    "1. Loads the custom vocabulary (`vocab.pkl`) containing the `word2id` dictionary built from WikiText-103\n",
    "2. Loads the saved checkpoint (`sbert_nli.pth`) which stores both the BERT backbone weights and classifier head weights\n",
    "3. Reconstructs the `BERT` model and `classifier_head` (Linear layer) using the saved hyperparameters\n",
    "4. Sets both models to evaluation mode (`.eval()`) to disable dropout\n",
    "\n",
    "---\n",
    "\n",
    "##### 2. Prediction Pipeline (`POST /predict`)\n",
    "\n",
    "When a user submits a premise-hypothesis pair, the following pipeline executes:\n",
    "\n",
    "![Pipeline](assets/pipeline.png)\n",
    "\n",
    "---\n",
    "\n",
    "##### 3. Frontend Interaction (`main.js`)\n",
    "\n",
    "The client-side JavaScript handles the user experience:\n",
    "\n",
    "1. **Form Submission** — Intercepts the form `submit` event, prevents page reload\n",
    "2. **Async Fetch** — Sends a `POST` request to `/predict` with JSON body `{ premise, hypothesis }`\n",
    "3. **Loading State** — Shows a spinner and disables the button during inference\n",
    "4. **Result Display** — Parses the JSON response and updates:\n",
    "   - The prediction label badge (color-coded: green = entailment, amber = neutral, red = contradiction)\n",
    "   - Confidence percentage (softmax probability of predicted class)\n",
    "   - Cosine similarity score (semantic relatedness between sentence embeddings)\n",
    "5. **Error Handling** — Catches network/server errors and displays an alert\n",
    "\n",
    "---\n",
    "\n",
    "##### 4. Design Philosophy\n",
    "\n",
    "The UI follows a **loft / minimal aesthetic**:\n",
    "- **Warm beige background** (`#f5f0eb`) for a calm, paper-like feel\n",
    "- **White card surface** with subtle `box-shadow` for depth\n",
    "- **Inter font family** for clean, modern typography\n",
    "- **CSS custom properties** (`:root` variables) for consistent theming\n",
    "- **Responsive layout** — single-column card, max-width 640px, scales on mobile\n",
    "- **Color-coded labels** — semantic colors for each NLI class (green/amber/red)\n",
    "\n",
    "---\n",
    "\n",
    "##### How to Run\n",
    "\n",
    "```bash\n",
    "# 1. Ensure model files exist\n",
    "#    model/sbert_nli.pth   (trained S-BERT checkpoint)\n",
    "#    model/vocab.pkl        (word2id vocabulary)\n",
    "\n",
    "# 2. Navigate to app directory\n",
    "cd app\n",
    "\n",
    "# 3. Install dependencies (if needed)\n",
    "pip install flask torch scikit-learn\n",
    "\n",
    "# 4. Start the server\n",
    "python app.py\n",
    "\n",
    "# 5. Open browser at http://localhost:5000\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1c600d9",
   "metadata": {},
   "source": [
    "#### Key Source Code\n",
    "\n",
    "Below are the core components of the web application for reference.\n",
    "\n",
    "---\n",
    "\n",
    "##### `app.py` — Flask Server (Routes Only)\n",
    "\n",
    "```python\n",
    "from flask import Flask, render_template, request, jsonify\n",
    "from utils import load_model, predict_nli\n",
    "\n",
    "app = Flask(__name__)\n",
    "bert_model, classifier_head, word2id, device = load_model(model_dir='../model')\n",
    "\n",
    "@app.route(\"/\")\n",
    "def index():\n",
    "    return render_template(\"index.html\")\n",
    "\n",
    "@app.route(\"/predict\", methods=[\"POST\"])\n",
    "def predict():\n",
    "    data = request.get_json()\n",
    "    premise = data.get(\"premise\", \"\").strip()\n",
    "    hypothesis = data.get(\"hypothesis\", \"\").strip()\n",
    "    if not premise or not hypothesis:\n",
    "        return jsonify({\"error\": \"Both premise and hypothesis are required\"}), 400\n",
    "    result = predict_nli(premise, hypothesis, bert_model, classifier_head, word2id, device)\n",
    "    return jsonify(result)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    app.run(debug=False, host=\"0.0.0.0\", port=5000)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "##### `utils.py` — Prediction Function (Core Logic)\n",
    "\n",
    "```python\n",
    "def predict_nli(premise, hypothesis, bert_model, classifier_head, word2id, device):\n",
    "    with torch.no_grad():\n",
    "        # Tokenize both sentences\n",
    "        p_ids, p_mask, p_seg = tokenize_sentence(premise, word2id)\n",
    "        h_ids, h_mask, h_seg = tokenize_sentence(hypothesis, word2id)\n",
    "\n",
    "        # Convert to tensors and move to device\n",
    "        p_ids_t = torch.LongTensor([p_ids]).to(device)\n",
    "        h_ids_t = torch.LongTensor([h_ids]).to(device)\n",
    "        # ... (attention masks and segment ids similarly)\n",
    "\n",
    "        # Get BERT hidden states\n",
    "        u_hidden = bert_model.get_last_hidden_state(p_ids_t, p_seg_t)\n",
    "        v_hidden = bert_model.get_last_hidden_state(h_ids_t, h_seg_t)\n",
    "\n",
    "        # Mean pooling → sentence embeddings\n",
    "        u = mean_pool(u_hidden, p_mask_t)  # (1, 768)\n",
    "        v = mean_pool(v_hidden, h_mask_t)  # (1, 768)\n",
    "\n",
    "        # Cosine similarity\n",
    "        sim = cosine_similarity(u.cpu().numpy(), v.cpu().numpy())[0, 0]\n",
    "\n",
    "        # Classification: [u; v; |u-v|] → Linear → Softmax\n",
    "        x = torch.cat([u, v, torch.abs(u - v)], dim=-1)  # (1, 2304)\n",
    "        logits = classifier_head(x)\n",
    "        probs = F.softmax(logits, dim=-1)\n",
    "        pred_class = torch.argmax(probs, dim=-1).item()\n",
    "\n",
    "    return {\"label\": LABEL_MAP[pred_class], \"confidence\": probs[0, pred_class].item(),\n",
    "            \"similarity\": float(sim), \"color\": LABEL_COLORS[pred_class]}\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "##### `main.js` — Client-Side Fetch Logic\n",
    "\n",
    "```javascript\n",
    "form.addEventListener('submit', async (e) => {\n",
    "    e.preventDefault();\n",
    "    const premise = document.getElementById('premise').value.trim();\n",
    "    const hypothesis = document.getElementById('hypothesis').value.trim();\n",
    "    // Show loading spinner\n",
    "    const response = await fetch('/predict', {\n",
    "        method: 'POST',\n",
    "        headers: { 'Content-Type': 'application/json' },\n",
    "        body: JSON.stringify({ premise, hypothesis }),\n",
    "    });\n",
    "    const data = await response.json();\n",
    "    // Update UI: label badge, confidence %, cosine similarity\n",
    "    resultTag.textContent = data.label;\n",
    "    resultTag.style.backgroundColor = data.color;\n",
    "    confidence.textContent = (data.confidence * 100).toFixed(1) + '%';\n",
    "    similarity.textContent = data.similarity.toFixed(4);\n",
    "});\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2be8f6f1",
   "metadata": {},
   "source": [
    "### References\n",
    "* Devlin, J., et al. (2019). \"BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding.\" https://aclanthology.org/N19-1423.pdf\n",
    "* Reimers, N. & Gurevych, I. (2019). \"Sentence-BERT: Sentence Embeddings using Siamese BERT-Networks.\" https://aclanthology.org/D19-1410/\n",
    "* WikiText-103 Dataset: https://huggingface.co/datasets/Salesforce/wikitext\n",
    "* SNLI Dataset: https://huggingface.co/datasets/stanfordnlp/snli\n",
    "* Bowman, S. R., et al. (2015). \"A large annotated corpus for learning natural language inference.\" https://aclanthology.org/D15-1075/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
